{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96521a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from requests.compat import urljoin\n",
    "import requests\n",
    "import glob\n",
    "import os\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "53e9621f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "86a5f4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install spacy\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7197f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open types.txt and read the types\n",
    "with open('../data/gold_standard_corpus.tsv', 'r') as f:\n",
    "    pmcids = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a03aab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PMC4792959',\n",
       " 'PMC4556948',\n",
       " 'PMC5993813',\n",
       " 'PMC3174205',\n",
       " 'PMC5962829',\n",
       " 'PMC3874094',\n",
       " 'PMC3792120',\n",
       " 'PMC4901335',\n",
       " 'PMC3581133',\n",
       " 'PMC2935479',\n",
       " 'PMC5225553',\n",
       " 'PMC5744400',\n",
       " 'PMC3281816',\n",
       " 'PMC3583137',\n",
       " 'PMC4022742',\n",
       " 'PMC3542345',\n",
       " 'PMC4452330',\n",
       " 'PMC4464872',\n",
       " 'PMC4872455',\n",
       " 'PMC3651197',\n",
       " 'PMC3362782',\n",
       " 'PMC5817132',\n",
       " 'PMC4313693',\n",
       " 'PMC4489904',\n",
       " 'PMC4552872',\n",
       " 'PMC5376652',\n",
       " 'PMC5070310',\n",
       " 'PMC5921292',\n",
       " 'PMC5641157',\n",
       " 'PMC3751948',\n",
       " 'PMC5472290',\n",
       " 'PMC4649626',\n",
       " 'PMC5502978',\n",
       " 'PMC4767726',\n",
       " 'PMC3897916',\n",
       " 'PMC5087830',\n",
       " 'PMC3585192',\n",
       " 'PMC5484670',\n",
       " 'PMC5259676',\n",
       " 'PMC3024232',\n",
       " 'PMC3097211',\n",
       " 'PMC5317055',\n",
       " 'PMC3648400',\n",
       " 'PMC5750880',\n",
       " 'PMC5100220',\n",
       " 'PMC4749753',\n",
       " 'PMC5344356',\n",
       " 'PMC5110973',\n",
       " 'PMC5708618',\n",
       " 'PMC3598673',\n",
       " 'PMC3751959',\n",
       " 'PMC5131611',\n",
       " 'PMC5891595',\n",
       " 'PMC3950279',\n",
       " 'PMC5972578',\n",
       " 'PMC5082793',\n",
       " 'PMC5487420',\n",
       " 'PMC5106849',\n",
       " 'PMC3858553',\n",
       " 'PMC3613406',\n",
       " 'PMC4167147',\n",
       " 'PMC3599585',\n",
       " 'PMC2761781',\n",
       " 'PMC3899050',\n",
       " 'PMC2481430',\n",
       " 'PMC5006041',\n",
       " 'PMC4790888',\n",
       " 'PMC3892176',\n",
       " 'PMC5126123',\n",
       " 'PMC4743178',\n",
       " 'PMC3322675',\n",
       " 'PMC3938772',\n",
       " 'PMC5832847',\n",
       " 'PMC4067685',\n",
       " 'PMC5260044',\n",
       " 'PMC3972685',\n",
       " 'PMC5982820',\n",
       " 'PMC4618948',\n",
       " 'PMC4831690',\n",
       " 'PMC4753424',\n",
       " 'PMC4340678',\n",
       " 'PMC2757916',\n",
       " 'PMC3439437',\n",
       " 'PMC3233425',\n",
       " 'PMC4603952',\n",
       " 'PMC4128218',\n",
       " 'PMC4940692',\n",
       " 'PMC6083812',\n",
       " 'PMC3304128',\n",
       " 'PMC4276928',\n",
       " 'PMC5395742',\n",
       " 'PMC3800775',\n",
       " 'PMC5703515',\n",
       " 'PMC3388477',\n",
       " 'PMC2474741',\n",
       " 'PMC2268669',\n",
       " 'PMC5350351',\n",
       " 'PMC5979449',\n",
       " 'PMC4531540',\n",
       " 'PMC4056076',\n",
       " 'PMC4554469',\n",
       " 'PMC3125229',\n",
       " 'PMC4189602',\n",
       " 'PMC4627615',\n",
       " 'PMC4921679',\n",
       " 'PMC5785827',\n",
       " 'PMC6069148',\n",
       " 'PMC4607270',\n",
       " 'PMC5521126',\n",
       " 'PMC5666160',\n",
       " 'PMC4978644',\n",
       " 'PMC5278426',\n",
       " 'PMC1762380',\n",
       " 'PMC4764649',\n",
       " 'PMC2424173',\n",
       " 'PMC4789058',\n",
       " 'PMC5891899',\n",
       " 'PMC2644373',\n",
       " 'PMC4931053',\n",
       " 'PMC5120353',\n",
       " 'PMC3867463',\n",
       " 'PMC5530572',\n",
       " 'PMC4540425',\n",
       " 'PMC3260253',\n",
       " 'PMC3189878',\n",
       " 'PMC3306317',\n",
       " 'PMC4263299',\n",
       " 'PMC5468280',\n",
       " 'PMC4465466',\n",
       " 'PMC5141432',\n",
       " 'PMC2720973',\n",
       " 'PMC5889178',\n",
       " 'PMC4349710',\n",
       " 'PMC3960246',\n",
       " 'PMC6037156',\n",
       " 'PMC5298922',\n",
       " 'PMC4494930',\n",
       " 'PMC3829848',\n",
       " 'PMC4954838',\n",
       " 'PMC4200311',\n",
       " 'PMC5315555',\n",
       " 'PMC5607173',\n",
       " 'PMC5730077',\n",
       " 'PMC5462789',\n",
       " 'PMC4109790',\n",
       " 'PMC5637056',\n",
       " 'PMC3291930',\n",
       " 'PMC5999171',\n",
       " 'PMC5920331',\n",
       " 'PMC5362908',\n",
       " 'PMC4816555',\n",
       " 'PMC4768280',\n",
       " 'PMC3494018',\n",
       " 'PMC5462825',\n",
       " 'PMC5706499',\n",
       " 'PMC4574349',\n",
       " 'PMC4320556',\n",
       " 'PMC3478264',\n",
       " 'PMC4405200',\n",
       " 'PMC5619751',\n",
       " 'PMC3020944',\n",
       " 'PMC5486778',\n",
       " 'PMC5356474',\n",
       " 'PMC5009309',\n",
       " 'PMC4359122',\n",
       " 'PMC4128749',\n",
       " 'PMC5134075',\n",
       " 'PMC5286694',\n",
       " 'PMC3228540',\n",
       " 'PMC5241644',\n",
       " 'PMC4899918',\n",
       " 'PMC2731044',\n",
       " 'PMC4302291',\n",
       " 'PMC3836741',\n",
       " 'PMC4414469',\n",
       " 'PMC5680628',\n",
       " 'PMC4794213',\n",
       " 'PMC4237798',\n",
       " 'PMC3895799',\n",
       " 'PMC4051664',\n",
       " 'PMC5302783',\n",
       " 'PMC2936521',\n",
       " 'PMC4923249',\n",
       " 'PMC5249225',\n",
       " 'PMC4871916',\n",
       " 'PMC4384350',\n",
       " 'PMC5528876',\n",
       " 'PMC4944956',\n",
       " 'PMC5770482',\n",
       " 'PMC3981893',\n",
       " 'PMC5779698',\n",
       " 'PMC4090160',\n",
       " 'PMC6069223',\n",
       " 'PMC5306324',\n",
       " 'PMC4417603',\n",
       " 'PMC3365900',\n",
       " 'PMC4262987',\n",
       " 'PMC4841026',\n",
       " 'PMC3502096',\n",
       " 'PMC4973533',\n",
       " 'PMC5244658',\n",
       " 'PMC3119053',\n",
       " 'PMC4766309',\n",
       " 'PMC5685608',\n",
       " 'PMC1971115',\n",
       " 'PMC5367487',\n",
       " 'PMC5617383',\n",
       " 'PMC3543396',\n",
       " 'PMC4294342',\n",
       " 'PMC3534334',\n",
       " 'PMC4964887',\n",
       " 'PMC6035403',\n",
       " 'PMC4912736',\n",
       " 'PMC3035578',\n",
       " 'PMC5004205',\n",
       " 'PMC4156656',\n",
       " 'PMC2233677',\n",
       " 'PMC4200867',\n",
       " 'PMC4914568',\n",
       " 'PMC2904378',\n",
       " 'PMC5216082',\n",
       " 'PMC3787392',\n",
       " 'PMC6023005',\n",
       " 'PMC3949526',\n",
       " 'PMC3435272',\n",
       " 'PMC3031208',\n",
       " 'PMC4892805',\n",
       " 'PMC5369143',\n",
       " 'PMC4906686',\n",
       " 'PMC3316545',\n",
       " 'PMC4051163',\n",
       " 'PMC4010498',\n",
       " 'PMC5227166',\n",
       " 'PMC3061204',\n",
       " 'PMC2386054',\n",
       " 'PMC3584731',\n",
       " 'PMC5426787',\n",
       " 'PMC5722940',\n",
       " 'PMC4462005',\n",
       " 'PMC3692464',\n",
       " 'PMC3836913',\n",
       " 'PMC4162557',\n",
       " 'PMC4542470',\n",
       " 'PMC5731848',\n",
       " 'PMC5026174',\n",
       " 'PMC6008929',\n",
       " 'PMC5959848',\n",
       " 'PMC2946298',\n",
       " 'PMC4499843',\n",
       " 'PMC5890137',\n",
       " 'PMC4352028',\n",
       " 'PMC4951087',\n",
       " 'PMC2987983',\n",
       " 'PMC3402998',\n",
       " 'PMC3115949',\n",
       " 'PMC4589515',\n",
       " 'PMC5510223',\n",
       " 'PMC2727484',\n",
       " 'PMC3464611',\n",
       " 'PMC4441378',\n",
       " 'PMC2478677',\n",
       " 'PMC2806293',\n",
       " 'PMC4647564',\n",
       " 'PMC4866616',\n",
       " 'PMC5530482',\n",
       " 'PMC2664782',\n",
       " 'PMC5816796',\n",
       " 'PMC3844564',\n",
       " 'PMC5770383',\n",
       " 'PMC5567653',\n",
       " 'PMC4697806',\n",
       " 'PMC5457019',\n",
       " 'PMC5297700',\n",
       " 'PMC4683867',\n",
       " 'PMC4244103',\n",
       " 'PMC2639708',\n",
       " 'PMC4791522',\n",
       " 'PMC5307887',\n",
       " 'PMC4311248',\n",
       " 'PMC4658497',\n",
       " 'PMC3611597',\n",
       " 'PMC1187897',\n",
       " 'PMC4991502',\n",
       " 'PMC3231843',\n",
       " 'PMC3859478',\n",
       " 'PMC5723443',\n",
       " 'PMC5217317',\n",
       " 'PMC6032655',\n",
       " 'PMC3029330',\n",
       " 'PMC4306119',\n",
       " 'PMC2443369',\n",
       " 'PMC4971634',\n",
       " 'PMC2895614',\n",
       " 'PMC4780767',\n",
       " 'PMC5078810',\n",
       " 'PMC4947190',\n",
       " 'PMC4976205',\n",
       " 'PMC2292144',\n",
       " 'PMC4808240',\n",
       " 'PMC3458065']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmcids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb41b77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Json_through_PMCID(pmcid):\n",
    "    base_url = \"https://www.ebi.ac.uk/europepmc/annotations_api/\"\n",
    "    article_url = urljoin(base_url,\n",
    "                          \"annotationsByArticleIds?articleIds=PMC%3A\" + pmcid + \"&provider=Europe%20PMC&format=JSON\")\n",
    "    r = requests.get(article_url)\n",
    "\n",
    "    if r.status_code == 200:\n",
    "        return r\n",
    "    else:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fa0a0dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_epmc_annotations_to_file(PMCids):\n",
    "    with open('../data/annotations_api.csv', 'w', newline='\\n') as f1:\n",
    "        test_writer = csv.writer(f1, delimiter='\\t', lineterminator='\\n')\n",
    "\n",
    "        # count = 0\n",
    "        for each_id in tqdm(PMCids):\n",
    "            # count = count+1\n",
    "            # print(each_test_pmc_id + '\\t' + str(count))\n",
    "            json_annotations = get_Json_through_PMCID(each_id[3:])  # Just the number is needed. So remove the PMC from the front\n",
    "            if json_annotations:\n",
    "                json_results = json_annotations.json()\n",
    "                try:\n",
    "                    pmc_id = json_results[0]['pmcid']\n",
    "                    # print(pmc_id)\n",
    "                    for each_annotation in json_results[0]['annotations']:\n",
    "                        exact = each_annotation['prefix'] + each_annotation['exact'] + each_annotation['postfix']\n",
    "                        token = each_annotation['tags'][0]['name']\n",
    "                        ner = each_annotation['type']\n",
    "                        row = [pmc_id, exact, token, ner]\n",
    "                        test_writer.writerow(row)\n",
    "                except(IndexError):\n",
    "                    print('no annotations found!! '+str(each_id))\n",
    "            else:\n",
    "                print('no annotations! '+str(each_id))\n",
    "                continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8fd337b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 300/300 [00:52<00:00,  5.76it/s]\n"
     ]
    }
   ],
   "source": [
    "get_epmc_annotations_to_file(pmcids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e7f046c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmcid</th>\n",
       "      <th>exact</th>\n",
       "      <th>token</th>\n",
       "      <th>ner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PMC4792959</td>\n",
       "      <td>Plant Biology, 260 Panama Street, Stanford, C</td>\n",
       "      <td>Panama</td>\n",
       "      <td>Organisms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PMC4792959</td>\n",
       "      <td>In plants, such barriers can either act before</td>\n",
       "      <td>plants</td>\n",
       "      <td>Organisms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PMC4792959</td>\n",
       "      <td>her act before (pre-pollination barriers) or a...</td>\n",
       "      <td>pollination</td>\n",
       "      <td>Gene Ontology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PMC4792959</td>\n",
       "      <td>barriers) or after pollination (post-pollinat...</td>\n",
       "      <td>pollination</td>\n",
       "      <td>Gene Ontology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PMC4792959</td>\n",
       "      <td>or after pollination (post-pollination barrie...</td>\n",
       "      <td>pollination</td>\n",
       "      <td>Gene Ontology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88185</th>\n",
       "      <td>PMC3458065</td>\n",
       "      <td>f erythrocytes from HIV-positive individual</td>\n",
       "      <td>HIV</td>\n",
       "      <td>Organisms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88186</th>\n",
       "      <td>PMC3458065</td>\n",
       "      <td>lts suggest that in HIV-positive individual</td>\n",
       "      <td>HIV</td>\n",
       "      <td>Organisms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88187</th>\n",
       "      <td>PMC3458065</td>\n",
       "      <td>ing high amounts of HIV by the presence of</td>\n",
       "      <td>HIV</td>\n",
       "      <td>Organisms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88188</th>\n",
       "      <td>PMC3458065</td>\n",
       "      <td>-gp160/120 on their membranes and this may produc</td>\n",
       "      <td>membranes</td>\n",
       "      <td>Gene Ontology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88189</th>\n",
       "      <td>PMC3458065</td>\n",
       "      <td>quantity due to the HIV binding through spe</td>\n",
       "      <td>HIV</td>\n",
       "      <td>Organisms</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88190 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            pmcid                                              exact  \\\n",
       "0      PMC4792959      Plant Biology, 260 Panama Street, Stanford, C   \n",
       "1      PMC4792959     In plants, such barriers can either act before   \n",
       "2      PMC4792959  her act before (pre-pollination barriers) or a...   \n",
       "3      PMC4792959   barriers) or after pollination (post-pollinat...   \n",
       "4      PMC4792959   or after pollination (post-pollination barrie...   \n",
       "...           ...                                                ...   \n",
       "88185  PMC3458065        f erythrocytes from HIV-positive individual   \n",
       "88186  PMC3458065        lts suggest that in HIV-positive individual   \n",
       "88187  PMC3458065        ing high amounts of HIV by the presence of    \n",
       "88188  PMC3458065  -gp160/120 on their membranes and this may produc   \n",
       "88189  PMC3458065        quantity due to the HIV binding through spe   \n",
       "\n",
       "             token            ner  \n",
       "0           Panama      Organisms  \n",
       "1           plants      Organisms  \n",
       "2      pollination  Gene Ontology  \n",
       "3      pollination  Gene Ontology  \n",
       "4      pollination  Gene Ontology  \n",
       "...            ...            ...  \n",
       "88185          HIV      Organisms  \n",
       "88186          HIV      Organisms  \n",
       "88187          HIV      Organisms  \n",
       "88188    membranes  Gene Ontology  \n",
       "88189          HIV      Organisms  \n",
       "\n",
       "[88190 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations_df = pd.read_csv('../data/annotations_api.csv', sep='\\t', names=['pmcid', 'exact', 'token', 'ner'])\n",
    "annotations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0468c00a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Organisms', 'Gene Ontology', 'Diseases', 'Gene_Proteins',\n",
       "       'Experimental Methods', 'Chemicals', 'Accession Numbers',\n",
       "       'Resources'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations_df['ner'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5618d114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmcid</th>\n",
       "      <th>exact</th>\n",
       "      <th>token</th>\n",
       "      <th>ner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PMC4792959</td>\n",
       "      <td>her act before (pre-pollination barriers) or a...</td>\n",
       "      <td>pollination</td>\n",
       "      <td>Gene Ontology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PMC4792959</td>\n",
       "      <td>barriers) or after pollination (post-pollinat...</td>\n",
       "      <td>pollination</td>\n",
       "      <td>Gene Ontology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PMC4792959</td>\n",
       "      <td>or after pollination (post-pollination barrie...</td>\n",
       "      <td>pollination</td>\n",
       "      <td>Gene Ontology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PMC4792959</td>\n",
       "      <td>Pre-pollination barriers can be spatial or tem...</td>\n",
       "      <td>pollination</td>\n",
       "      <td>Gene Ontology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PMC4792959</td>\n",
       "      <td>ecies, whereas post-pollination barriers come ...</td>\n",
       "      <td>pollination</td>\n",
       "      <td>Gene Ontology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88126</th>\n",
       "      <td>PMC3458065</td>\n",
       "      <td>ated for 7 to 10 days and assayed for syncytiu...</td>\n",
       "      <td>syncytium formation</td>\n",
       "      <td>Gene Ontology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88127</th>\n",
       "      <td>PMC3458065</td>\n",
       "      <td>is able to inhibit syncytium formation (loss ...</td>\n",
       "      <td>syncytium formation</td>\n",
       "      <td>Gene Ontology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88134</th>\n",
       "      <td>PMC3458065</td>\n",
       "      <td>end-point dilution assay in MT-2 cells cultu</td>\n",
       "      <td>assay</td>\n",
       "      <td>Experimental Methods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88156</th>\n",
       "      <td>PMC3458065</td>\n",
       "      <td>e IgG anti-HIV binding to erythrocyte membrane.</td>\n",
       "      <td>membrane</td>\n",
       "      <td>Gene Ontology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88188</th>\n",
       "      <td>PMC3458065</td>\n",
       "      <td>-gp160/120 on their membranes and this may produc</td>\n",
       "      <td>membranes</td>\n",
       "      <td>Gene Ontology</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16570 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            pmcid                                              exact  \\\n",
       "2      PMC4792959  her act before (pre-pollination barriers) or a...   \n",
       "3      PMC4792959   barriers) or after pollination (post-pollinat...   \n",
       "4      PMC4792959   or after pollination (post-pollination barrie...   \n",
       "5      PMC4792959  Pre-pollination barriers can be spatial or tem...   \n",
       "7      PMC4792959  ecies, whereas post-pollination barriers come ...   \n",
       "...           ...                                                ...   \n",
       "88126  PMC3458065  ated for 7 to 10 days and assayed for syncytiu...   \n",
       "88127  PMC3458065   is able to inhibit syncytium formation (loss ...   \n",
       "88134  PMC3458065       end-point dilution assay in MT-2 cells cultu   \n",
       "88156  PMC3458065   e IgG anti-HIV binding to erythrocyte membrane.    \n",
       "88188  PMC3458065  -gp160/120 on their membranes and this may produc   \n",
       "\n",
       "                     token                   ner  \n",
       "2              pollination         Gene Ontology  \n",
       "3              pollination         Gene Ontology  \n",
       "4              pollination         Gene Ontology  \n",
       "5              pollination         Gene Ontology  \n",
       "7              pollination         Gene Ontology  \n",
       "...                    ...                   ...  \n",
       "88126  syncytium formation         Gene Ontology  \n",
       "88127  syncytium formation         Gene Ontology  \n",
       "88134                assay  Experimental Methods  \n",
       "88156             membrane         Gene Ontology  \n",
       "88188            membranes         Gene Ontology  \n",
       "\n",
       "[16570 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations_df_other = annotations_df[annotations_df['ner'].isin(['Gene Ontology', 'Experimental Methods', 'Accession Numbers', 'Resources'])]\n",
    "annotations_df_other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ffd11fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get unique PMCIDs\n",
    "# unique_pmcids = annotations_df_other['pmcid'].unique()url = f\"https://www.ebi.ac.uk/europepmc/webservices/rest/{pmcid}/fullTextXML\"\n",
    "# unique_pmcids\n",
    "\n",
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "# import re\n",
    "\n",
    "# def get_full_text_xml(pmcid):\n",
    "#     url = f\"https://www.ebi.ac.uk/europepmc/webservices/rest/{pmcid}/fullTextXML\"\n",
    "#     response = requests.get(url)\n",
    "#     if response.status_code == 200:\n",
    "#         soup = BeautifulSoup(response.content, 'xml')\n",
    "#         p_tags = soup.find_all('p')\n",
    "#         p_texts = [tag.get_text() for tag in p_tags]\n",
    "#         return p_texts\n",
    "#     else:\n",
    "#         return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a09a2e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_pmcids = annotations_df_other['pmcid'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf5eb240",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_text_xml(pmcid):\n",
    "    path = f\"../data/300_articles_source_files/{pmcid}.xml\"\n",
    "    try:\n",
    "        with open(path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "        \n",
    "        soup = BeautifulSoup(content, 'lxml-xml')  # Use lxml-xml parser\n",
    "        plain_tags = soup.find_all('plain')\n",
    "        plain_texts = [tag.get_text() for tag in plain_tags]\n",
    "        return plain_texts\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {pmcid}.xml not found.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2be6f435",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3dfe5245",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 297/297 [00:31<00:00,  9.34it/s]\n"
     ]
    }
   ],
   "source": [
    "def find_sentence_with_substring(string_list, substring):\n",
    "    for text in string_list:\n",
    "        sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "        for sentence in sentences:\n",
    "            if substring in sentence:\n",
    "                return sentence\n",
    "    return None\n",
    "\n",
    "# def adjust_token_for_context(sentence, token, ner_):\n",
    "#     words = sentence.split()\n",
    "#     punctuation_marks = [',', '.', '?', '!']\n",
    "\n",
    "#     # Adjust token for larger term if token is a substring and does not contain specific punctuation\n",
    "#     if ner_ in ['Gene Ontology', 'Experimental Methods']:\n",
    "#         for word in words:\n",
    "#             if token in word and word != token and not any(mark in token for mark in punctuation_marks):\n",
    "#                 token = word  # Update the token to the larger term\n",
    "#                 break\n",
    "\n",
    "#     # Extend the token if 'assay', 'assays', 'insertion', or 'insertions' follows the token and the preceding word is in upper or mixed case\n",
    "#     for key_word in ['assay', 'insertion', 'insertions', 'assays']:\n",
    "#         if key_word in words:\n",
    "#             key_word_index = words.index(key_word)\n",
    "#             if key_word_index > 0 and not words[key_word_index - 1].islower():\n",
    "#                 if words[key_word_index - 1].lower() not in ['the', 'an', 'a']:\n",
    "#                     token = words[key_word_index - 1] + ' ' + token  # Update the token\n",
    "#                     token = token  # Remove parentheses\n",
    "\n",
    "#     return token.replace('(', '').replace(')', '')\n",
    "\n",
    "def adjust_token_for_context(sentence, token, ner_):\n",
    "    words = sentence.split()\n",
    "    punctuation_marks = [',', '.', '?', '!']\n",
    "    extended_tokens = []\n",
    "\n",
    "    # Adjust token for larger term if token is a substring and does not contain specific punctuation\n",
    "    if ner_ in ['Gene Ontology', 'Experimental Methods']:\n",
    "        for word in words:\n",
    "            if token in word and word != token and not any(mark in token for mark in punctuation_marks):\n",
    "                extended_tokens.append(word)  # Add the matched larger term to the list\n",
    "\n",
    "    # Extend the token if 'assay', 'assays', 'insertion', or 'insertions' follows the token and the preceding word is in upper or mixed case\n",
    "    for key_word in ['assay', 'insertion', 'insertions', 'assays']:\n",
    "        if key_word in words:\n",
    "            key_word_index = words.index(key_word)\n",
    "            if key_word_index > 0 and not words[key_word_index - 1].islower():\n",
    "                if words[key_word_index - 1].lower() not in ['the', 'an', 'a']:\n",
    "                    extended_token = words[key_word_index - 1] + ' ' + token  # Form the extended token\n",
    "                    extended_token = extended_token.replace('(', '').replace(')', '')\n",
    "                    extended_tokens.append(extended_token)  # Add the extended token to the list\n",
    "\n",
    "    return extended_tokens if extended_tokens else [token]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def process_pmcid(df, pmcid, p_texts):\n",
    "    sentences_data = {}\n",
    "    for _, row in df[df['pmcid'] == pmcid].iterrows():\n",
    "        sentence = find_sentence_with_substring(p_texts, row['exact'])\n",
    "        if sentence:\n",
    "            if sentence not in sentences_data:\n",
    "                sentences_data[sentence] = set()\n",
    "\n",
    "            updated_tokens = adjust_token_for_context(sentence, row['token'], row['ner'])\n",
    "            for updated_token in updated_tokens:\n",
    "                sentences_data[sentence].add((updated_token, row['ner']))\n",
    "\n",
    "    return [[pmcid, sentence, list(ner_tags)] for sentence, ner_tags in sentences_data.items()]\n",
    "\n",
    "# # The rest of the script remains the same\n",
    "# def process_pmcid(df, pmcid, p_texts):\n",
    "#     sentences_data = {}\n",
    "#     for _, row in df[df['pmcid'] == pmcid].iterrows():\n",
    "#         sentence = find_sentence_with_substring(p_texts, row['exact'])\n",
    "#         if sentence:\n",
    "#             if sentence not in sentences_data:\n",
    "#                 sentences_data[sentence] = set()\n",
    "\n",
    "#             updated_token = adjust_token_for_context(sentence, row['token'],row['ner'])\n",
    "#             sentences_data[sentence].add((updated_token, row['ner']))\n",
    "\n",
    "#     return [[pmcid, sentence, list(ner_tags)] for sentence, ner_tags in sentences_data.items()]\n",
    "\n",
    "final_data = []\n",
    "\n",
    "for pmcid in tqdm(unique_pmcids):\n",
    "    p_texts = get_full_text_xml(pmcid)\n",
    "    if p_texts:\n",
    "        processed_data = process_pmcid(annotations_df_other, pmcid, p_texts)\n",
    "        final_data.extend(processed_data)\n",
    "\n",
    "# Convert to DataFrame\n",
    "final_df = pd.DataFrame(final_data, columns=['pmcid', 'sentence', 'ner'])\n",
    "\n",
    "# Save as TSV\n",
    "final_df.to_csv('../data/xxx6.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b966fa1",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1924422297.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[18], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    viral capture assay,\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "viral capture assay,\n",
    "interspecific pollination,\n",
    "N-glycosylation.\n",
    "flow cytometry assay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b68d7e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29974ca4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cdc703",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ada52ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 297/297 [03:31<00:00,  1.40it/s]\n"
     ]
    }
   ],
   "source": [
    "def merge_overlapping_tags(ner_tags):\n",
    "    # Sort by start index\n",
    "    sorted_tags = sorted(ner_tags, key=lambda x: x[0])\n",
    "    merged_tags = []\n",
    "    current_tag = None\n",
    "\n",
    "    for tag in sorted_tags:\n",
    "        if current_tag is None:\n",
    "            current_tag = tag\n",
    "        else:\n",
    "            # Check for overlap or adjacency and same entity type\n",
    "            if (tag[0] <= current_tag[1] or tag[0] == current_tag[1] + 1) and tag[3] == current_tag[3]:\n",
    "                # Extend the current tag if the new tag ends later\n",
    "                current_tag[1] = max(current_tag[1], tag[1])\n",
    "                current_tag[2] = current_tag[2] if current_tag[2] in tag[2] else current_tag[2] + ' ' + tag[2]  # Merge tokens\n",
    "            else:\n",
    "                merged_tags.append(current_tag)\n",
    "                current_tag = tag\n",
    "\n",
    "    if current_tag is not None:\n",
    "        merged_tags.append(current_tag)\n",
    "\n",
    "    return merged_tags\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def remove_duplicate_tags(ner_tags):\n",
    "    return [list(t) for t in set(tuple(tag) for tag in ner_tags)]\n",
    "\n",
    "def adjust_spans_for_context(sentence, start_index, end_index, token):\n",
    "    words = sentence.split()\n",
    "    word_positions = [sentence.find(word) for word in words]\n",
    "\n",
    "    # Adjust span for larger term if token is a substring\n",
    "    for i, word in enumerate(words):\n",
    "        if token in word and word != token:\n",
    "            start_index = min(start_index, word_positions[i])\n",
    "            end_index = max(end_index, word_positions[i] + len(word))\n",
    "            token = word  # Update the token to the larger term\n",
    "            break\n",
    "\n",
    "    # Extend the span if 'assay' follows the token and the preceding word is in upper or mixed case\n",
    "    for i, word in enumerate(words):\n",
    "        if word.lower() == 'assay' or word.lower() == 'insertion' and i > 0 and not words[i - 1].islower():\n",
    "            prev_word_start = word_positions[i - 1]\n",
    "            start_index = min(start_index, prev_word_start)\n",
    "            token = words[i - 1] + ' ' + token  # Update the token\n",
    "            break\n",
    "\n",
    "    return start_index, end_index, token\n",
    "\n",
    "def process_pmcid(df, pmcid, p_texts):\n",
    "    sentences_data = {}\n",
    "    for _, row in df[df['pmcid'] == pmcid].iterrows():\n",
    "        sentence = find_sentence_with_substring(p_texts, row['exact'])\n",
    "        if sentence:\n",
    "            if sentence not in sentences_data:\n",
    "                sentences_data[sentence] = []\n",
    "\n",
    "            start_index = sentence.find(row['token'])\n",
    "            if start_index != -1:\n",
    "                end_index = start_index + len(row['token'])\n",
    "                start_index, end_index, updated_token = adjust_spans_for_context(sentence, start_index, end_index, row['token'])\n",
    "                sentences_data[sentence].append([start_index, end_index, updated_token, row['ner']])\n",
    "\n",
    "    for sentence, tags in sentences_data.items():\n",
    "        sentences_data[sentence] = remove_duplicate_tags(tags)\n",
    "        sentences_data[sentence] = merge_overlapping_tags(sentences_data[sentence])\n",
    "\n",
    "    return [(pmcid, sentence, ner_tags) for sentence, ner_tags in sentences_data.items()]\n",
    "\n",
    "final_data = []\n",
    "\n",
    "for pmcid in tqdm(unique_pmcids):\n",
    "    p_texts = get_full_text_xml(pmcid)\n",
    "    if p_texts:\n",
    "        processed_data = process_pmcid(annotations_df_other, pmcid, p_texts)\n",
    "        final_data.extend(processed_data)\n",
    "\n",
    "# Convert to DataFrame\n",
    "final_df = pd.DataFrame(final_data, columns=['pmcid', 'sentence', 'ner'])\n",
    "\n",
    "# Save as TSV\n",
    "final_df.to_csv('../data/xxx4.tsv', sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b39347",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f77e3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263bb788",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c693b78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77286fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 297/297 [04:00<00:00,  1.23it/s]\n"
     ]
    }
   ],
   "source": [
    "def merge_overlapping_tags(ner_tags):\n",
    "    # Sort by start index\n",
    "    sorted_tags = sorted(ner_tags, key=lambda x: x[0])\n",
    "    merged_tags = []\n",
    "    current_tag = None\n",
    "\n",
    "    for tag in sorted_tags:\n",
    "        if current_tag is None:\n",
    "            current_tag = tag\n",
    "        else:\n",
    "            # Check for overlap or adjacency\n",
    "            if tag[0] <= current_tag[1]:\n",
    "                # Extend the current tag if the new tag ends later\n",
    "                current_tag[1] = max(current_tag[1], tag[1])\n",
    "                current_tag[2] = current_tag[2] + ' ' + tag[2]  # Merge tokens\n",
    "                current_tag[3] = current_tag[3] + ' ' + tag[3]  # Merge entity types\n",
    "            else:\n",
    "                merged_tags.append(current_tag)\n",
    "                current_tag = tag\n",
    "\n",
    "    if current_tag is not None:\n",
    "        merged_tags.append(current_tag)\n",
    "\n",
    "    return merged_tags\n",
    "\n",
    "def remove_duplicate_tags(ner_tags):\n",
    "    return [list(t) for t in set(tuple(tag) for tag in ner_tags)]\n",
    "\n",
    "def process_pmcid(df, pmcid, p_texts):\n",
    "    sentences_data = {}\n",
    "    for _, row in df[df['pmcid'] == pmcid].iterrows():\n",
    "        sentence = find_sentence_with_substring(p_texts, row['exact'])\n",
    "        if sentence:\n",
    "            if sentence not in sentences_data:\n",
    "                sentences_data[sentence] = []\n",
    "\n",
    "            start_index = sentence.find(row['token'])\n",
    "            if start_index != -1:\n",
    "                end_index = start_index + len(row['token'])\n",
    "                sentences_data[sentence].append([start_index, end_index, row['token'], row['ner']])\n",
    "\n",
    "    for sentence, tags in sentences_data.items():\n",
    "        sentences_data[sentence] = remove_duplicate_tags(tags)\n",
    "        sentences_data[sentence] = merge_overlapping_tags(sentences_data[sentence])\n",
    "\n",
    "    return [(pmcid, sentence, ner_tags) for sentence, ner_tags in sentences_data.items()]\n",
    "\n",
    "final_data = []\n",
    "\n",
    "for pmcid in tqdm(unique_pmcids):\n",
    "    p_texts = get_full_text_xml(pmcid)\n",
    "    if p_texts:\n",
    "        processed_data = process_pmcid(annotations_df_other, pmcid, p_texts)\n",
    "        final_data.extend(processed_data)\n",
    "\n",
    "# Convert to DataFrame\n",
    "final_df = pd.DataFrame(final_data, columns=['pmcid', 'sentence', 'ner'])\n",
    "\n",
    "# Save as TSV\n",
    "final_df.to_csv('../data/xxx2.tsv', sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6af5a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca99286",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8824f0c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dead588d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abef5bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ae2e01fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 297/297 [03:38<00:00,  1.36it/s]\n"
     ]
    }
   ],
   "source": [
    "def process_pmcid(df, pmcid):\n",
    "    p_texts = get_full_text_xml(pmcid)\n",
    "    if p_texts is None:\n",
    "        return []\n",
    "\n",
    "    sentences_data = {}\n",
    "    # Iterate over rows with the same PMCID\n",
    "    for _, row in df[df['pmcid'] == pmcid].iterrows():\n",
    "        sentence = find_sentence_with_substring(p_texts, row['exact'])\n",
    "        if sentence:\n",
    "            if sentence not in sentences_data:\n",
    "                sentences_data[sentence] = []\n",
    "            \n",
    "            # Find the start and end indices of the token in the sentence\n",
    "            start_index = sentence.find(row['token'])\n",
    "            if start_index != -1:  # Token found in the sentence\n",
    "                end_index = start_index + len(row['token'])\n",
    "                sentences_data[sentence].append([start_index, end_index, row['token'], row['ner']])\n",
    "\n",
    "    # Convert the dictionary to a list of tuples\n",
    "    processed_data = [(pmcid, sentence, ner_tags) for sentence, ner_tags in sentences_data.items()]\n",
    "    return processed_data\n",
    "\n",
    "final_data = []\n",
    "\n",
    "for pmcid in tqdm(unique_pmcids):\n",
    "    processed_data = process_pmcid(df, pmcid)\n",
    "    final_data.extend(processed_data)\n",
    "\n",
    "# Convert to DataFrame\n",
    "final_df = pd.DataFrame(final_data, columns=['pmcid', 'sentence', 'ner'])\n",
    "\n",
    "# Save as TSV\n",
    "final_df.to_csv('../data/xxx1.tsv', sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5755cae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'her act before (pre-pollination barriers) or after '"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"In plants, such barriers can either act before (pre-pollination barriers) or after pollination (post-pollination barriers).\"[32:83]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "376af9fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tqdm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 50\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [(pmcid, sentence, ner_tags) \u001b[38;5;28;01mfor\u001b[39;00m sentence, ner_tags \u001b[38;5;129;01min\u001b[39;00m sentences_data\u001b[38;5;241m.\u001b[39mitems()]\n\u001b[1;32m     48\u001b[0m final_data \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pmcid \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtqdm\u001b[49m(unique_pmcids):\n\u001b[1;32m     51\u001b[0m     p_texts \u001b[38;5;241m=\u001b[39m get_full_text_xml(pmcid)\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m p_texts:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tqdm' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa5074a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770872ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86c1e0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eecfef27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing clean_CD_GP_DS_OG_train.csv:   0%| | 8/80013 [00:06<17:20:43,  1.28it"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This work aimed to assess whether GR3027 improves motor incoordination, spatial learning, and circadian rhythms of activity in rats with HE.  [[127, 131, 'rats', 'OG'], [137, 139, 'HE', 'DS'], [34, 40, 'GR3027', 'CD'], [80, 88, 'learning', 'Gene Ontology'], [94, 111, 'circadian rhythms', 'Gene Ontology']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing clean_CD_GP_DS_OG_train.csv:   0%| | 12/80013 [00:09<17:47:22,  1.25i"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In both hyperammonemic and PCS rats, GR3027 restores motor coordination, spatial memory in the Morris water maze, and spatial learning in the radial maze.  [[31, 35, 'rats', 'OG'], [37, 43, 'GR3027', 'CD'], [81, 87, 'memory', 'Gene Ontology'], [126, 134, 'learning', 'Gene Ontology']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing clean_CD_GP_DS_OG_train.csv:   0%| | 13/80013 [00:10<17:29:07,  1.27i"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GR3027 also partially restores circadian rhythms of ambulatory and vertical activity in PCS rats.  [[92, 96, 'rats', 'OG'], [0, 6, 'GR3027', 'CD'], [31, 48, 'circadian rhythms', 'Gene Ontology']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing clean_CD_GP_DS_OG_train.csv:   0%| | 24/80013 [00:18<16:54:14,  1.31i"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Increased GABAergic tone induces motor incoordination, and extracellular GABA in cerebellum correlates with motor incoordination in rats (9). α1-Containing GABAA receptors are likely involved in the motor incoordination since benzodiazepines induce ataxia by enhancing activation of α1-containing GABAA receptors (27).  [[156, 171, 'GABAA receptors', 'GP'], [297, 312, 'GABAA receptors', 'GP'], [249, 255, 'ataxia', 'DS'], [132, 136, 'rats', 'OG'], [226, 241, 'benzodiazepines', 'CD'], [59, 72, 'extracellular', 'Gene Ontology']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing clean_CD_GP_DS_OG_train.csv:   0%| | 25/80013 [00:19<16:53:04,  1.32i"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Furthermore, overactivation of GABAA receptors by the agonists diazepam and muscimol or the neurosteroids allopregnanolone and 3α,21-dihydroxy-5α-pregnan-20-one (THDOC) impairs spatial learning and memory in the Morris water maze (19, 33, 34).  [[31, 46, 'GABAA receptors', 'GP'], [63, 71, 'diazepam', 'CD'], [76, 84, 'muscimol', 'CD'], [106, 122, 'allopregnanolone', 'CD'], [185, 193, 'learning', 'Gene Ontology'], [198, 204, 'memory', 'Gene Ontology']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing clean_CD_GP_DS_OG_train.csv:   0%| | 26/80013 [00:20<16:46:53,  1.32i"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GABAergic tone is increased in the cerebellum of rats with chronic hyperammonemia and HE because of increased extracellular GABA and increased levels of neurosteroids acting as positive modulators of GABAA receptors (allopregnanolone, THDOC) (12).  [[200, 215, 'GABAA receptors', 'GP'], [86, 88, 'HE', 'DS'], [49, 53, 'rats', 'OG'], [67, 81, 'hyperammonemia', 'DS'], [217, 233, 'allopregnanolone', 'CD'], [110, 123, 'extracellular', 'Gene Ontology']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing clean_CD_GP_DS_OG_train.csv:   0%| | 31/80013 [00:24<17:25:12,  1.28i\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m entities \u001b[38;5;241m=\u001b[39m \u001b[38;5;28meval\u001b[39m(entities_str) \u001b[38;5;28;01mif\u001b[39;00m entities_str \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNone\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m entities_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[1;32m     27\u001b[0m updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, annotation \u001b[38;5;129;01min\u001b[39;00m annotations_df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m annotation[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexact\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m sentence:\n\u001b[1;32m     31\u001b[0m         span \u001b[38;5;241m=\u001b[39m find_span(sentence, annotation[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/site-packages/pandas/core/frame.py:1400\u001b[0m, in \u001b[0;36mDataFrame.iterrows\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1398\u001b[0m using_cow \u001b[38;5;241m=\u001b[39m using_copy_on_write()\n\u001b[1;32m   1399\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues):\n\u001b[0;32m-> 1400\u001b[0m     s \u001b[38;5;241m=\u001b[39m \u001b[43mklass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1401\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m using_cow \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mis_single_block:\n\u001b[1;32m   1402\u001b[0m         s\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39madd_references(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/site-packages/pandas/core/series.py:509\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    507\u001b[0m         data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 509\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43msanitize_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    511\u001b[0m     manager \u001b[38;5;241m=\u001b[39m get_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.data_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/site-packages/pandas/core/construction.py:533\u001b[0m, in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[1;32m    531\u001b[0m         dtype \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m    532\u001b[0m     data \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mitem_from_zerodim(data)\n\u001b[0;32m--> 533\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mrange\u001b[39m):\n\u001b[1;32m    534\u001b[0m     \u001b[38;5;66;03m# GH#16804\u001b[39;00m\n\u001b[1;32m    535\u001b[0m     data \u001b[38;5;241m=\u001b[39m range_to_ndarray(data)\n\u001b[1;32m    536\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def find_span(sentence, substring):\n",
    "    start = sentence.find(substring)\n",
    "    if start != -1:\n",
    "        return [start, start + len(substring)]\n",
    "    return None\n",
    "\n",
    "annotations_df = pd.read_csv('../data/annotations_api.csv', delimiter='\\t', names=['pmcid', 'exact', 'token', 'ner'])\n",
    "annotations_df = annotations_df[annotations_df['ner'].isin(['Gene Ontology', 'Experimental Methods', 'Accession Numbers', 'Resources'])]\n",
    "\n",
    "folder_path = '../data/CD_GP_DS_OG_test'\n",
    "for file in os.listdir(folder_path):\n",
    "    if file.endswith('.csv'):\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Initialize an empty list to store relevant rows\n",
    "        relevant_rows = []\n",
    "\n",
    "        for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=f\"Processing {file}\"):\n",
    "            sentence = row[0]\n",
    "            entities_str = row[1]\n",
    "            entities = eval(entities_str) if entities_str != 'None' and entities_str.startswith('[') else []\n",
    "            updated = False\n",
    "\n",
    "            for _, annotation in annotations_df.iterrows():\n",
    "                if annotation['exact'] in sentence:\n",
    "                    span = find_span(sentence, annotation['token'])\n",
    "                    if span and all(isinstance(e, list) and (span[0] > e[1] or span[1] < e[0]) for e in entities):\n",
    "                        entities.append([span[0], span[1], annotation['token'], annotation['ner']])\n",
    "                        updated = True\n",
    "\n",
    "            # Add the row to the relevant_rows list if it contains updated entities\n",
    "            if updated:\n",
    "                relevant_rows.append([sentence, str(entities)])\n",
    "                print(sentence, str(entities))\n",
    "\n",
    "        # Create a new DataFrame from the list of relevant rows\n",
    "        new_df = pd.DataFrame(relevant_rows, columns=df.columns)\n",
    "\n",
    "        # Save to a new file\n",
    "        new_file_path = os.path.join(folder_path, f\"new_{file}\")\n",
    "        new_df.to_csv(new_file_path, index=False)\n",
    "\n",
    "print(\"Processing completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "96db9cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing clean_CD_GP_DS_OG_train.csv:   1%| | 515/80013 [06:30<16:43:24,  1.32\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m entities \u001b[38;5;241m=\u001b[39m \u001b[38;5;28meval\u001b[39m(entities_str) \u001b[38;5;28;01mif\u001b[39;00m entities_str \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNone\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m entities_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[1;32m     30\u001b[0m updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, annotation \u001b[38;5;129;01min\u001b[39;00m annotations_df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m annotation[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexact\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m sentence:\n\u001b[1;32m     34\u001b[0m         span \u001b[38;5;241m=\u001b[39m find_span(sentence, annotation[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/site-packages/pandas/core/frame.py:1400\u001b[0m, in \u001b[0;36mDataFrame.iterrows\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1398\u001b[0m using_cow \u001b[38;5;241m=\u001b[39m using_copy_on_write()\n\u001b[1;32m   1399\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues):\n\u001b[0;32m-> 1400\u001b[0m     s \u001b[38;5;241m=\u001b[39m \u001b[43mklass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1401\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m using_cow \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mis_single_block:\n\u001b[1;32m   1402\u001b[0m         s\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39madd_references(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/site-packages/pandas/core/series.py:425\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    422\u001b[0m name \u001b[38;5;241m=\u001b[39m ibase\u001b[38;5;241m.\u001b[39mmaybe_extract_name(name, data, \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m))\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 425\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[43mensure_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    428\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_dtype(dtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def find_span(sentence, substring):\n",
    "    start = sentence.find(substring)\n",
    "    if start != -1:\n",
    "        return [start, start + len(substring)]\n",
    "    return None\n",
    "\n",
    "annotations_df = pd.read_csv('../data/annotations_api.csv', delimiter='\\t', names=['pmcid', 'exact', 'token', 'ner'])\n",
    "annotations_df = annotations_df[annotations_df['ner'].isin(['Gene Ontology', 'Experimental Methods', 'Accession Numbers', 'Resources'])]\n",
    "\n",
    "folder_path = '../data/CD_GP_DS_OG_test'\n",
    "for file in os.listdir(folder_path):\n",
    "    if file.endswith('.csv'):\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Open a new file for writing\n",
    "        new_file_path = os.path.join(folder_path, f\"new_{file}\")\n",
    "        with open(new_file_path, 'w') as new_file:\n",
    "            # Write headers\n",
    "            new_file.write(','.join(df.columns) + '\\n')\n",
    "\n",
    "            for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=f\"Processing {file}\"):\n",
    "                sentence = row[0]\n",
    "                entities_str = row[1]\n",
    "                entities = eval(entities_str) if entities_str != 'None' and entities_str.startswith('[') else []\n",
    "                updated = False\n",
    "\n",
    "                for _, annotation in annotations_df.iterrows():\n",
    "                    if annotation['exact'] in sentence:\n",
    "                        span = find_span(sentence, annotation['token'])\n",
    "                        if span and all(isinstance(e, list) and (span[0] > e[1] or span[1] < e[0]) for e in entities):\n",
    "                            entities.append([span[0], span[1], annotation['token'], annotation['ner']])\n",
    "                            updated = True\n",
    "\n",
    "                # Write the updated row to the new file\n",
    "                if updated:\n",
    "                    new_file.write(f\"{sentence},{str(entities)}\\n\")\n",
    "\n",
    "print(\"Processing completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4023880c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Present address: Boyce-Thompson Institute for Plant Research, 533 Tower Road, Ithaca, New York 14853, USA',\n",
       " 'Present address: Carnegie Institution for Science, Department of Plant Biology, 260 Panama Street, Stanford, California 94305, USA',\n",
       " 'Species-specific gamete recognition is a key premise to ensure reproductive success and the maintenance of species boundaries. During plant pollen tube (PT) reception, gametophyte interactions likely allow the species-specific recognition of signals from the PT (male gametophyte) by the embryo sac (female gametophyte), resulting in PT rupture, sperm release, and double fertilization. This process is impaired in interspecific crosses between Arabidopsis thaliana and related species, leading to PT overgrowth and a failure to deliver the sperm cells. Here we show that ARTUMES (ARU) specifically regulates the recognition of interspecific PTs in A. thaliana. ARU, identified in a genome-wide association study (GWAS), exclusively influences interspecific—but not intraspecific—gametophyte interactions. ARU encodes the OST3/6 subunit of the oligosaccharyltransferase complex conferring protein N-glycosylation. Our results suggest that glycosylation patterns of cell surface proteins may represent an important mechanism of gametophyte recognition and thus speciation.',\n",
       " '\\nSpecies-specific gamete recognition is needed to maintain species boundaries. Here, Müller et al. show that ARTUMES regulates pollen tube recognition between different Arabidopsis species, representing the first gene known to exclusively influence inter- but not intraspecific gamete interaction in plants.',\n",
       " 'Species evolve and are maintained by a variety of hybridization barriers that prevent interspecific gene flow and thus the formation of potentially unviable or sterile hybrids1. To date, the molecular basis of hybridization barriers is still poorly understood. In plants, such barriers can either act before (pre-pollination barriers) or after pollination (post-pollination barriers). Pre-pollination barriers can be spatial or temporal patterns preventing plants from being pollinated by pollen from a different species, whereas post-pollination barriers come into play only after an interspecific pollination event occurs and can be further divided into pre- and post-zygotic barriers2. The latter usually act at the genomic level (for example, incompatibilities leading to hybrid lethality or sterility), while pre-zygotic barriers prevent the formation of a zygote and usually rely on direct cell–cell communication between the male and female tissues. Most species pairs are isolated by a complex interplay of different types of isolation barriers. Whereas barriers that prevent fertilization (both pre-pollination and pre-zygotic barriers) often represent the most important means to reduce interspecific gene flow, post-zygotic hybridization barriers appear to contribute less to reproductive isolation in many species pairs3.']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL to request\n",
    "url = \"https://www.ebi.ac.uk/europepmc/webservices/rest/PMC4792959/fullTextXML\"\n",
    "\n",
    "# Make the request\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Parse the content using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, 'xml')\n",
    "    \n",
    "    # Find all <p> tags\n",
    "    p_tags = soup.find_all('p')\n",
    "\n",
    "    # Extract text from each <p> tag\n",
    "    p_texts = [tag.get_text() for tag in p_tags]\n",
    "else:\n",
    "    p_texts = f\"Failed to retrieve data: Status code {response.status_code}\"\n",
    "\n",
    "p_texts[:5]  # Display first 5 paragraphs as an example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "96ba4237",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# Function to find the sentence containing the substring\n",
    "def find_sentence_with_substring(string_list, substring):\n",
    "    for text in string_list:\n",
    "        # Split the text into sentences\n",
    "        sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "        for sentence in sentences:\n",
    "            if substring in sentence:\n",
    "                return sentence\n",
    "    return None\n",
    "\n",
    "# Find the sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "345d9547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'For digital droplet PCR on ovule cDNA, the UBC9 assay was performed as an EvaGreen assay, whereas ARU transcripts were detected using a gene-specific probe (5′-FAM- TACTGCACAAAGGTTG -MGB-3′).'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "substring_to_check =  'vule cDNA, the UBC9 assay was performed as an' \n",
    "\n",
    "found_sentence = find_sentence_with_substring(p_texts, substring_to_check)\n",
    "found_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "38b1a2d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "found = any('ubstrate-specific N-glycosylation of proteins in yeas' in s for s in p_texts)\n",
    "found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492d1a74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
