{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "930f199b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stirunag/falconframes_env/lib/python3.10/site-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_sci_sm' (0.5.4) was trained with spaCy v3.7.4 and may not be 100% compatible with the current version (3.7.0). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n",
      "/home/stirunag/falconframes_env/lib/python3.10/site-packages/spacy/language.py:2170: FutureWarning: Possible set union at position 6328\n",
      "  deserializers[\"tokenizer\"] = lambda p: self.tokenizer.from_disk(  # type: ignore[union-attr]\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import regex as re\n",
    "import io\n",
    "import gzip\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import lxml\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "import scispacy\n",
    "\n",
    "# Load SciSpacy model\n",
    "nlp = spacy.load(\"en_core_sci_sm\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f2dec99d-c14c-4a67-a394-c9d38cb4b215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping dictionaries for section tagging\n",
    "titleMapsBody = {\n",
    "    'INTRO': ['introduction', 'background', 'related literature', 'literature review', 'objective', 'aim ', 'purpose of this study', 'study (purpose|aim|aims)', r'\\d+\\. (purpose|aims|aim)', '(aims|aim|purpose) of the study', '(the|drug|systematic|book) review', 'review of literature', 'related work', 'recent advance'],\n",
    "    'METHODS': ['supplement', 'methods and materials', 'method', 'material', 'experimental procedure', 'implementation', 'methodology', 'treatment', 'statistical analysis', \"experimental\", r'\\d+\\. experimental$', 'experimental (section|evaluation|design|approach|protocol|setting|set up|investigation|detail|part|perspective|tool)', \"the study\", r'\\d+\\. the study$', \"protocol\", \"protocols\", 'study protocol', 'construction and content', r'experiment \\d+', '^experiments$', 'analysis', 'utility', 'design', r'\\d+\\. theory$', \"theory\", 'theory and ', 'theory of '],\n",
    "    'RESULTS': ['result', 'finding', 'diagnosis'],\n",
    "    'DISCUSS': ['discussion', 'management of', r'\\d+\\. management', 'safety and tolerability', 'limitations', 'perspective', 'commentary', r'\\d+\\. comment'],\n",
    "    'CONCL': ['conclusion', 'key message', 'future', 'summary', 'recommendation', 'implications for clinical practice', 'concluding remark'],\n",
    "    'CASE': ['case study report', 'case report', 'case presentation', 'case description', r'case \\d+', r'\\d+\\. case', 'case summary', 'case history'],\n",
    "    'ACK_FUND': ['funding', 'acknowledgement', 'acknowledgment', 'financial disclosure'],\n",
    "    'AUTH_CONT': ['author contribution', 'authors\\' contribution', 'author\\'s contribution'],\n",
    "    'COMP_INT': ['competing interest', 'conflict of interest', 'conflicts of interest', 'disclosure', 'declaration'],\n",
    "    'ABBR': ['abbreviation'],\n",
    "    'SUPPL': ['supplemental data', 'supplementary file', 'supplemental file', 'supplementary data', 'supplementary figure', 'supplemental figure', 'supporting information', 'supplemental file', 'supplemental material', 'supplementary material', 'supplement material', 'additional data files', 'supplemental information', 'supplementary information', 'supplemental information', 'supporting information', 'supplemental table', 'supplementary table', 'supplement table', 'supplementary material', 'supplemental material', 'supplement material', 'supplementary video']\n",
    "}\n",
    "\n",
    "titleExactMapsBody = {\n",
    "    'INTRO': [\"aim\", \"aims\", \"purpose\", \"purposes\", \"purpose/aim\", \"purpose of study\", \"review\", \"reviews\", \"minireview\"],\n",
    "    'METHODS': [\"experimental\", \"the study\", \"protocol\", \"protocols\"],\n",
    "    'DISCUSS': [\"management\", \"comment\", \"comments\"],\n",
    "    'CASE': [\"case\", \"cases\"]\n",
    "}\n",
    "\n",
    "titleMapsBack = {\n",
    "    'REF': ['reference', 'literature cited', 'references', 'bibliography'],\n",
    "    'ACK_FUND': ['funding', 'acknowledgement', 'acknowledgment', 'acknowlegement', 'acknowlegement', 'open access', 'financial support', 'grant', 'author note', 'financial disclosure'],\n",
    "    'ABBR': ['abbreviation', 'glossary'],\n",
    "    'COMP_INT': ['competing interest', 'conflict of interest', 'conflicts of interest', 'disclosure', 'declaration', 'conflicts', 'interest'],\n",
    "    'SUPPL': ['supplementary', 'supporting information', 'supplemental', 'web extra material'],\n",
    "    'APPENDIX': ['appendix', 'appendices'],\n",
    "    'AUTH_CONT': ['author', 'contribution']\n",
    "}\n",
    "\n",
    "def createSecTag(soup, secType):\n",
    "    secTag = soup.new_tag('SecTag')\n",
    "    secTag['type'] = secType\n",
    "    return secTag\n",
    "\n",
    "def titlePartialMatch(title, secFlag):\n",
    "    matchKeys = []\n",
    "    if secFlag == 'body':\n",
    "        for key, patterns in titleMapsBody.items():\n",
    "            if any(re.search(pattern, title.lower()) for pattern in patterns):\n",
    "                matchKeys.append(key)\n",
    "    elif secFlag == 'back':\n",
    "        for key, patterns in titleMapsBack.items():\n",
    "            if any(re.search(pattern, title.lower()) for pattern in patterns):\n",
    "                matchKeys.append(key)\n",
    "    if len(matchKeys) > 0:\n",
    "        return ','.join(matchKeys)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def titleExactMatch(title, secFlag):\n",
    "    if secFlag == 'body':\n",
    "        for key, patterns in titleExactMapsBody.items():\n",
    "            if any(pattern == title.lower() for pattern in patterns):\n",
    "                return key\n",
    "    return None\n",
    "\n",
    "def section_tag(soup):\n",
    "    # Add Figure section\n",
    "    for fig in soup.find_all('fig', recursive=True):\n",
    "        if fig.find_all('fig', recursive=True):\n",
    "            continue\n",
    "        else:\n",
    "            fig_tag = createSecTag(soup, 'FIG')\n",
    "            fig.wrap(fig_tag)\n",
    "    # Add Table section\n",
    "    for table in soup.find_all('table-wrap', recursive=True):\n",
    "        if table.find_all('table-wrap', recursive=True):\n",
    "            continue\n",
    "        else:\n",
    "            table_tag = createSecTag(soup, 'TABLE')\n",
    "            table.wrap(table_tag)\n",
    "    # Get front section\n",
    "    if soup.front:\n",
    "        if soup.front.abstract:\n",
    "            secAbs = createSecTag(soup, 'ABSTRACT')\n",
    "            soup.front.abstract.wrap(secAbs)\n",
    "        if soup.front.find('kwd-group'):\n",
    "            secKwd = createSecTag(soup, 'KEYWORD')\n",
    "            soup.front.find('kwd-group').wrap(secKwd)\n",
    "    # Get sec tags from body\n",
    "    secFlag = 'body'\n",
    "    if soup.body:\n",
    "        for sec in soup.body.find_all('sec', recursive=False):\n",
    "            if sec.title:\n",
    "                mappedTitle = titleExactMatch(sec.title.text.strip(), secFlag)\n",
    "                if mappedTitle is None:\n",
    "                    mappedTitle = titlePartialMatch(sec.title.text.strip(), secFlag)\n",
    "                if mappedTitle:\n",
    "                    secBody = createSecTag(soup, mappedTitle)\n",
    "                    sec.wrap(secBody)\n",
    "    # Get back sections\n",
    "    secFlag = 'back'\n",
    "    if soup.back:\n",
    "        for sec in soup.back.find_all(['sec', 'ref-list', 'app-group', 'ack', 'glossary', 'notes', 'fn-group'], recursive=False):\n",
    "            if sec.title:\n",
    "                mappedTitle = titlePartialMatch(sec.title.text.strip(), secFlag)\n",
    "                if mappedTitle:\n",
    "                    secBack = createSecTag(soup, mappedTitle)\n",
    "                    sec.wrap(secBack)\n",
    "            else:\n",
    "                if sec.name == 'ref-list':\n",
    "                    secRef = createSecTag(soup, 'REF')\n",
    "                    sec.wrap(secRef)\n",
    "\n",
    "\n",
    "# Function to read XML or GZ files and split into individual articles\n",
    "def getfileblocks(file_path, document_flag):\n",
    "    sub_file_blocks = []\n",
    "    if file_path.endswith('.gz'):\n",
    "        open_func = lambda x: gzip.open(x, 'rt', encoding='utf8')\n",
    "    else:\n",
    "        open_func = lambda x: open(x, 'r', encoding='utf8')\n",
    "\n",
    "    try:\n",
    "        with open_func(file_path) as fh:\n",
    "            content = fh.read()\n",
    "            if document_flag in ['f', 'a']:\n",
    "                # Split content by <!DOCTYPE article ...> or <article ...> tags\n",
    "                articles = re.split(r'(?=<!DOCTYPE article|<article(?![\\w-]))', content)\n",
    "                sub_file_blocks = [article.strip() for article in articles if article.strip() and '<!DOCTYPE' not in article]\n",
    "            else:\n",
    "                print('ERROR: unknown document type :' + document_flag)\n",
    "    except Exception as e:\n",
    "        print('Error processing file: ' + str(file_path))\n",
    "        print(e)\n",
    "\n",
    "    return sub_file_blocks\n",
    "\n",
    "\n",
    "\n",
    "# Function to split text into sentences using SciSpacy\n",
    "def sentence_split(text, sent_id):\n",
    "    sentences = []\n",
    "    doc = nlp(text)\n",
    "    for sent in doc.sents:\n",
    "        sentences.append(sent.text.strip())\n",
    "    #sentences = text.split('.')\n",
    "    return sent_id + len(sentences), sentences\n",
    "\n",
    "# Function to process <p> tags\n",
    "def process_p_tag(gch, sent_id):\n",
    "    sentences = []\n",
    "    p_children = gch.contents\n",
    "    if len(p_children) == 1 and (not p_children[0].string) and (p_children[0].name in [\"ext-link\", \"e-mail\", \"uri\", \"inline-supplementary-material\",\n",
    "                                           \"related-article\", \"related-object\", \"address\", \"alternatives\", \"array\",\n",
    "                                           \"funding-source\", \"inline-graphic\"]):\n",
    "        pass  # Ignore\n",
    "    else:\n",
    "        text = gch.get_text(separator=' ', strip=True)\n",
    "        _, sents = sentence_split(text, sent_id)\n",
    "        sentences.extend(sents)\n",
    "        sent_id += len(sents)\n",
    "    return sent_id, sentences\n",
    "\n",
    "# Function to process nested tags and collect sentences\n",
    "def call_sentence_tags(ch, sent_id):\n",
    "    sentences = []\n",
    "    for gch in ch.children:\n",
    "        if isinstance(gch, str):\n",
    "            continue  # Skip strings directly under ch\n",
    "        if gch.name in ['article-title', 'title', 'subtitle', 'trans-title', 'trans-subtitle', 'alt-title', 'label', 'td', 'th']:\n",
    "            if gch.find('p', recursive=False):\n",
    "                sent_id, sub_sentences = call_sentence_tags(gch, sent_id)\n",
    "                sentences.extend(sub_sentences)\n",
    "            else:\n",
    "                text = gch.get_text(separator=' ', strip=True)\n",
    "                _, sents = sentence_split(text, sent_id)\n",
    "                sentences.extend(sents)\n",
    "                sent_id += len(sents)\n",
    "        elif gch.name in [\"sec\", \"fig\", \"statement\", \"div\", \"boxed-text\", \"list\", \"list-item\", \"disp-quote\", \"speech\",\n",
    "                          \"fn-group\", \"fn\", \"def-list\", \"def-item\", \"def\", \"ack\", \"array\", \"table-wrap\", \"table\",\n",
    "                          \"tbody\", \"thead\", \"tr\", \"caption\", \"answer\", \"sec-meta\", \"glossary\", \"question\", \"question-wrap\"]:\n",
    "            sent_id, sub_sentences = call_sentence_tags(gch, sent_id)\n",
    "            sentences.extend(sub_sentences)\n",
    "        elif gch.name == 'p':\n",
    "            sent_id, sub_sentences = process_p_tag(gch, sent_id)\n",
    "            sentences.extend(sub_sentences)\n",
    "        else:\n",
    "            text = gch.get_text(separator=' ', strip=True)\n",
    "            if text:\n",
    "                _, sents = sentence_split(text, sent_id)\n",
    "                sentences.extend(sents)\n",
    "                sent_id += len(sents)\n",
    "    return sent_id, sentences\n",
    "\n",
    "# Function to process the front section\n",
    "def process_front(front):\n",
    "    sent_id = 1\n",
    "    sections = {}\n",
    "    if front.find('article-meta'):\n",
    "        art_meta = front.find('article-meta')\n",
    "        for ch in art_meta.find_all(recursive=False):\n",
    "            if ch.name in ['title-group', 'supplement', 'supplementary-material', 'abstract', 'trans-abstract',\n",
    "                           'kwd-group', 'funding-group']:\n",
    "                section_title = ch.name\n",
    "                sent_id, sentences = call_sentence_tags(ch, sent_id)\n",
    "                if sentences:\n",
    "                    sections[section_title] = sentences\n",
    "            else:\n",
    "                pass  # Ignore other tags\n",
    "    return sent_id, sections\n",
    "\n",
    "# Function to process the body section\n",
    "def process_body(body, sent_id):\n",
    "    sections = {}\n",
    "    for ch in body.find_all(recursive=False):\n",
    "        if ch.name == 'p':\n",
    "            sent_id, sentences = process_p_tag(ch, sent_id)\n",
    "            if 'body' in sections:\n",
    "                sections['body'].extend(sentences)\n",
    "            else:\n",
    "                sections['body'] = sentences\n",
    "        elif ch.name in ['sec', 'ack', 'alternatives', 'array', 'preformat', 'fig', 'fig-group', 'question-wrap',\n",
    "                         'question-wrap-group', 'list', 'table-wrap-group', 'table-wrap', 'display-formula',\n",
    "                         'display-formula-group', 'def-list', 'list', 'supplementary-material', 'kwd-group',\n",
    "                         'funding-group', 'statement', 'fig']:\n",
    "            # Sections with titles\n",
    "            title = ch.find('title')\n",
    "            if title:\n",
    "                section_title = title.get_text(separator=' ', strip=True)\n",
    "            else:\n",
    "                section_title = ch.name\n",
    "            sent_id, sentences = call_sentence_tags(ch, sent_id)\n",
    "            if sentences:\n",
    "                if section_title in sections:\n",
    "                    sections[section_title].extend(sentences)\n",
    "                else:\n",
    "                    sections[section_title] = sentences\n",
    "        else:\n",
    "            pass  # Ignore other tags\n",
    "    return sent_id, sections\n",
    "\n",
    "# Function to process the back section\n",
    "def process_back(back, sent_id):\n",
    "    sections = {}\n",
    "    for ch in back.find_all(recursive=False):\n",
    "        if ch.name in ['sec', 'p', 'ack', 'alternatives', 'array', 'preformat', 'fig', 'fig-group', 'question-wrap',\n",
    "                 'question-wrap-group', 'list', 'table-wrap-group', 'table-wrap', 'display-formula',\n",
    "                 'display-formula-group', 'def-list', 'list', 'supplementary-material', 'kwd-group',\n",
    "                 'funding-group', 'statement', 'ref-list', 'glossary']:\n",
    "            # Sections with titles\n",
    "            if ch.name == 'ref-list':\n",
    "                sent_id, sentences = reference_sents(ch, sent_id)\n",
    "                if sentences:\n",
    "                    sections[ch.name] = sentences\n",
    "            else:\n",
    "                title = ch.find('title')\n",
    "                if title:\n",
    "                    section_title = title.get_text(separator=' ', strip=True)\n",
    "                else:\n",
    "                    section_title = ch.name\n",
    "                sent_id, sentences = call_sentence_tags(ch, sent_id)\n",
    "                if sentences:\n",
    "                    if section_title in sections:\n",
    "                        sections[section_title].extend(sentences)\n",
    "                    else:\n",
    "                        sections[section_title] = sentences\n",
    "        else:\n",
    "            pass  # Ignore other tags\n",
    "    return sent_id, sections\n",
    "\n",
    "# Function to process reference sentences\n",
    "def reference_sents(ref_list, sent_id):\n",
    "    sentences = []\n",
    "    for ch in ref_list.children:\n",
    "        if isinstance(ch, str):\n",
    "            continue  # Skip strings directly under ref_list\n",
    "        if ch.name == 'ref':\n",
    "            sub_text = ''\n",
    "            for gch in ch.children:\n",
    "                if isinstance(gch, str):\n",
    "                    continue\n",
    "                sub_text += \" \" + \" \".join([d.string for d in gch.descendants if d.string])\n",
    "            sent_id, sents = sentence_split(sub_text, sent_id)\n",
    "            sentences.extend(sents)\n",
    "        elif ch.name in [\"sec\", \"fig\", \"statement\", \"div\", \"boxed-text\", \"list\", \"list-item\", \"disp-quote\", \"speech\",\n",
    "                         \"fn-group\", \"fn\", \"def-list\", \"def-item\", \"def\", \"ack\", \"array\", \"table-wrap\", \"table\",\n",
    "                         \"tbody\", \"caption\", \"answer\", \"sec-meta\", \"glossary\", \"question\", \"question-wrap\"]:\n",
    "            sent_id, sub_sentences = call_sentence_tags(ch, sent_id)\n",
    "            sentences.extend(sub_sentences)\n",
    "        else:\n",
    "            pass  # Ignore other tags\n",
    "    return sent_id, sentences\n",
    "\n",
    "# Function to process each article and collect sentences\n",
    "def process_full_text(each_file):\n",
    "    # Replace body tag with orig_body to prevent BeautifulSoup from removing it\n",
    "    each_file = each_file.replace('<body>', '<orig_body>')\n",
    "    each_file = each_file.replace('<body ', '<orig_body ')\n",
    "    each_file = each_file.replace('</body>', '</orig_body>')\n",
    "    try:\n",
    "        xml_soup = BeautifulSoup(each_file, 'lxml')\n",
    "        # Remove extra html and body tags added by BeautifulSoup\n",
    "        if xml_soup.html:\n",
    "            xml_soup.html.unwrap()\n",
    "        if xml_soup.body:\n",
    "            xml_soup.body.unwrap()\n",
    "        if xml_soup.find('orig_body'):\n",
    "            xml_soup.find('orig_body').name = 'body'\n",
    "\n",
    "        # Apply section tagging\n",
    "        section_tag(xml_soup)\n",
    "\n",
    "        sent_id = 1\n",
    "\n",
    "        # Extract article IDs\n",
    "        article_ids = {}\n",
    "        for id_tag in xml_soup.find_all('article-id'):\n",
    "            id_type = id_tag.get('pub-id-type', 'unknown')\n",
    "            article_ids[id_type] = id_tag.text.strip()\n",
    "        if not article_ids:\n",
    "            print('No article IDs found')\n",
    "            return None\n",
    "\n",
    "        # Extract attributes from the <article> tag\n",
    "        article_tag = xml_soup.find('article')\n",
    "        if article_tag:\n",
    "            open_status = article_tag.get('open-status', '')\n",
    "            article_type = article_tag.get('article-type', '')\n",
    "        else:\n",
    "            open_status = ''\n",
    "            article_type = ''\n",
    "\n",
    "        # Initialize sections dictionary\n",
    "        sections = {}\n",
    "\n",
    "        # Process sections under SecTag\n",
    "        for sec_tag in xml_soup.find_all('SecTag'):\n",
    "            sec_type = sec_tag.get('type', 'unknown')\n",
    "            if sec_type not in sections:\n",
    "                sections[sec_type] = []\n",
    "            # Exclude nested 'SecTag's to avoid duplicate text\n",
    "            for nested_sec in sec_tag.find_all('SecTag', recursive=True):\n",
    "                nested_sec.extract()\n",
    "            sent_id, sentences = call_sentence_tags(sec_tag, sent_id)\n",
    "            sections[sec_type].extend(sentences)\n",
    "            sent_id += len(sentences)\n",
    "\n",
    "        # Process front section if not already processed\n",
    "        if 'ABSTRACT' not in sections and xml_soup.article.find('front'):\n",
    "            sent_id, front_sections = process_front(xml_soup.article.find('front'))\n",
    "            for k, v in front_sections.items():\n",
    "                if k in sections:\n",
    "                    sections[k].extend(v)\n",
    "                else:\n",
    "                    sections[k] = v\n",
    "\n",
    "        # Process body section if not already processed\n",
    "        if xml_soup.article.find('body'):\n",
    "            sent_id, body_sections = process_body(xml_soup.article.find('body'), sent_id)\n",
    "            for k, v in body_sections.items():\n",
    "                if k in sections:\n",
    "                    sections[k].extend(v)\n",
    "                else:\n",
    "                    sections[k] = v\n",
    "\n",
    "        # Process back section if not already processed\n",
    "        if xml_soup.article.find('back'):\n",
    "            sent_id, back_sections = process_back(xml_soup.article.find('back'), sent_id)\n",
    "            for k, v in back_sections.items():\n",
    "                if k in sections:\n",
    "                    sections[k].extend(v)\n",
    "                else:\n",
    "                    sections[k] = v\n",
    "\n",
    "        # Create the data dictionary\n",
    "        data = {\n",
    "        'article_ids': article_ids,\n",
    "        'open_status': open_status,\n",
    "        'article_type': article_type,\n",
    "        'sections': sections\n",
    "    }\n",
    "        return data\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "# Main function to process each article and write to output file\n",
    "def process_each_article(each_file_path, out_file, document_flag):\n",
    "    files_list = getfileblocks(each_file_path, document_flag)\n",
    "    with open(out_file, 'w') as out:\n",
    "        for each_file in tqdm(files_list, desc=\"Processing Articles\", disable=False):\n",
    "            data = process_full_text(each_file)\n",
    "            if data:\n",
    "                out.write(json.dumps(data) + '\\n')\n",
    "\n",
    "# # Entry point\n",
    "# if __name__ == '__main__':\n",
    "#     parser = argparse.ArgumentParser(description='Process XML files and output sentences.')\n",
    "#     parser.add_argument('--input', help='Input XML or GZ file path', required=True)\n",
    "#     parser.add_argument('--output', help='Output JSONL file path', required=True)\n",
    "#     parser.add_argument('--type', help='Document type: f for full text, a for abstract', choices=['f', 'a'], required=True)\n",
    "#     args = parser.parse_args()\n",
    "\n",
    "#     process_each_article(args.input, args.output, args.type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83c6382c-eec5-4af7-91d3-e261b6f4cbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output.jsonl\t\t   patch-28-01-2023-21.xml.gz\n",
      "patch-07-10-2024-0.xml.gz  sentenciser.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d3f67204",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file =  'patch-28-01-2023-21.xml.gz' #'patch-07-10-2024-0.xml.gz'\n",
    "output_file ='output.jsonl' \n",
    "document_flag = 'f'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6f7ec2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#process_each_article(input_file, output_file, document_flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aaaebc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = getfileblocks(input_file, document_flag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "42eb2ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2a8cce26-b5b4-4f64-bf2a-a36047b8e5cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'article_ids': {'pmcid': '9878372',\n",
       "  'publisher-id': 'v12i1e41533',\n",
       "  'pmid': '36630158',\n",
       "  'doi': '10.2196/41533'},\n",
       " 'open_status': 'O',\n",
       " 'article_type': 'research-article',\n",
       " 'sections': {'ABSTRACT': ['Background Measuring vital signs (VS) is an important aspect of clinical care but is time-consuming and requires multiple pieces of equipment and trained staff.',\n",
       "   'Interest in the contactless measurement of VS has grown since the COVID-19 pandemic, including in nonclinical situations.',\n",
       "   'Lifelight is an app being developed as a medical device for the contactless measurement of VS using remote photoplethysmography (rPPG) via the camera on smart devices.',\n",
       "   'The VISION-D (Measurement of Vital Signs by Lifelight Software in Comparison to the Standard of Care—Development) and VISION-V (Validation) studies demonstrated the accuracy of Lifelight compared with standard-of-care measurement of blood pressure, pulse rate, and respiratory rate, supporting the certification of Lifelight as a class I Conformité Européenne (CE) medical device.',\n",
       "   'Objective To support further development of the Lifelight app, the observational VISION Multisite Development (VISION-MD) study is collecting high-quality data from a broad range of patients, including those with VS measurements outside the normal healthy range and patients who are critically ill.',\n",
       "   'Methods The study is recruiting adults (aged ≥16 years) who are inpatients (some critically ill), outpatients, and healthy volunteers, aiming to cover a broad range of normal and clinically relevant VS values; there are no exclusion criteria.',\n",
       "   'High-resolution 60-second videos of the face are recorded by the Lifelight app while simultaneously measuring VS using standard-of-care methods (automated sphygmomanometer for blood pressure; finger clip sensor for pulse rate and oxygen saturation; manual counting of respiratory rate).',\n",
       "   'Feedback from patients and nurses who use Lifelight is collected via a questionnaire.',\n",
       "   'Data to estimate the cost-effectiveness of Lifelight compared with standard-of-care VS measurement are also being collected.',\n",
       "   'A new method for rPPG signal processing is currently being developed, based on the identification of small areas of high-quality signals in each individual.',\n",
       "   'Anticipated recruitment is 1950 participants, with the expectation that data from approximately 1700 will be used for software development.',\n",
       "   'Data from 250 participants will be retained to test the performance of Lifelight against predefined performance targets.',\n",
       "   'Results Recruitment began in May 2021 but was hindered by the restrictions instigated during the COVID-19 pandemic.',\n",
       "   'The development of data processing methodology is in progress.',\n",
       "   'The data for analysis will become available from September 2022, and the algorithms will be refined continuously to improve clinical accuracy.',\n",
       "   'The performance of Lifelight compared with that of the standard-of-care measurement of VS will then be tested.',\n",
       "   'Recruitment will resume if further data are required.',\n",
       "   'The analyses are expected to be completed in early 2023.',\n",
       "   'Conclusions This study will support the refinement of data collection and processing toward the development of a robust app that is suitable for routine clinical use.',\n",
       "   'Trial Registration ClinicalTrials.gov NCT04763746; https://clinicaltrials.gov/ct2/show/NCT04763746 International Registered Report Identifier (IRRID) DERR1-10.2196/41533'],\n",
       "  'KEYWORD': ['general practice vital signs/methods vital signs/standards photoplethysmography remote photoplethysmography rPPG Lifelight contactless software'],\n",
       "  'INTRO': ['Introduction',\n",
       "   \"The measurement of vital signs (VS) provides important information about a patient's health and, importantly, a change in VS may herald a deterioration in health [ 1 ].\",\n",
       "   'Despite the importance of VS to inform clinical decision-making, the accuracy and timeliness of measurement are in need of improvement [ 2 - 4 ].',\n",
       "   'However, the measurement of VS requires using multiple pieces of equipment that need to be calibrated regularly and is time-consuming.',\n",
       "   'It may also be uncomfortable and stressful for patients, potentially compromising the utility of the information obtained.',\n",
       "   'Standard-of-care medical equipment is not suitable for patients who require regular measurement of VS in the home or community setting to monitor long-term health conditions because of cost, the complexity of the measuring processes, and the need for calibration of equipment.',\n",
       "   'A study of 725 patients reported that while 53% followed at least 10 of the recommended steps necessary for accurate blood pressure (BP) measurement at home, only 1% followed all 15 recommendations [ 5 ].',\n",
       "   'Thus, home measurement of VS is important—and respiratory rate and pulse rate in particular—but requires several pieces of equipment (BP monitor and pulse oximeter) and for patients to be educated in best practices.',\n",
       "   'The COVID-19 pandemic highlighted the need for remote or contactless VS measurement to reduce the risk of infection, which can be operated by people without specific medical training.',\n",
       "   'The shift away from face-to-face to digital consultations during the pandemic also points to the need for easy but accurate measurement of VS.',\n",
       "   'Photoplethysmography (PPG) is an optical technique based on the measurement of the light reflected from the skin surface, which changes due to volumetric changes in the facial blood vessels; small variations in perfusion provide valuable information about the cardiovascular system [ 6 ].',\n",
       "   'PPG has been used to measure pulse rate [ 7 , 8 ], oxygen saturation [ 9 ], BP [ 10 , 11 ], and respiratory rate [ 7 , 12 ] and to detect atrial fibrillation [ 13 ].',\n",
       "   'Lifelight (Xim Ltd) is an app being developed for the contactless measurement of VS using remote PPG (rPPG) via the camera on smart devices such as phones and tablets.',\n",
       "   'The app captures the average color of the region of interest 30 times every second for 60 seconds and sends this as red, green, and blue values to the server for further processing.',\n",
       "   'VS values are obtained from the green channel.',\n",
       "   'The VISION-D (Measurement of Vital Signs by Lifelight Software in Comparison to the Standard of Care-Development) study measured VS in 8585 patients and healthy volunteers simultaneously using Lifelight and standard-of-care methods.',\n",
       "   'The data were used for machine learning to improve the accuracy of the Lifelight algorithms used to calculate VS.',\n",
       "   'The smaller VISION-V (Measurement of Vital Signs by Lifelight Software in Comparison to the Standard of Care–Validation) study demonstrated the accuracy of the Lifelight app compared with standard-of-care methods for measuring pulse rate, respiratory rate, and diastolic BP [ 14 ], providing the basis for the current class I Conformité Européenne (CE) registration [ 15 ].',\n",
       "   'However, some of the methods used in the VISION-V study differed from the procedures described in the standard for BP measurement (ISO81060-2) because of the novel nature of the Lifelight technology.',\n",
       "   'Furthermore, these early studies did not include participants with BP values across the full range likely to be encountered in clinical practice.',\n",
       "   'To further improve the accuracy of Lifelight, the Measurement of Vital Signs by Lifelight Software in Comparison to the Standard of Care–Multisite Development (VISION-MD) study is collecting data from a wide range of outpatients, inpatients, and patients who are critically ill, and across the full range of skin tones, for use in machine learning.',\n",
       "   'In VISION-D and VISION-V, full-face videos were recorded, but a high proportion of data were not usable.',\n",
       "   'Thus, high-resolution full-face videos are being recorded to maximize the opportunity for machine learning.',\n",
       "   'These data will also be used to evaluate alternative methods of defining the region of interest, as the full face includes areas that are not relevant (eg, areas covered by facial hair and areas that illicit a poor signal).',\n",
       "   'Given that only a small proportion of the raw video signal is relevant for rPPG measurement of VS (1%-2%), we are developing ways to enhance data collection and signal processing.',\n",
       "   'Video recordings will be of higher resolution than those in the VISION-V and VISION-D studies, and data processing is focusing on the midface region (cheeks, nose, and top of the lip), rather than the whole face; these areas are computationally efficient for rPPG because of their large area and good-quality signal [ 16 ] but are not likely to be affected by autoregulation of cerebral blood flow (which discounts the forehead) [ 17 ].',\n",
       "   'We are also developing a method to identify small regions of interest in the midface in each participant where signal quality is the highest.',\n",
       "   'This approach is expected to overcome some of the challenges of rPPG for routine clinical use, such as positioning of the participant relative to the light source.',\n",
       "   'VISION-MD (Clinicaltrials.gov NCT04763746) aims to advance the development and accuracy of the Lifelight app as a noninvasive and easy-to-use device to measure VS in hospitals and the community.',\n",
       "   'The study will collect data from a broad range of patients to further develop the accuracy of Lifelight to a level sufficient for clinical applications, including screening and monitoring of cardiovascular disease.',\n",
       "   'The initial data collected are being used for machine learning; later data will be used to test the accuracy of Lifelight compared with standard-of-care measurement of VS.',\n",
       "   'Thus, the primary objective of VISION-MD is to further develop the Lifelight algorithms across extensive clinical ranges, including critically ill patients and in patients with different skin tones.',\n",
       "   'Secondary objectives are: (1) to improve and test the efficacy of Lifelight estimates for BP, pulse rate, respiratory rate, and oxygen saturation in multiple clinical settings (eg, critical care, outpatient clinics, and general hospital wards); (2) to evaluate the impact of variables on the accuracy of Lifelight VS measurements (eg, age, sex, temperature, health condition, medication, skin tone, and ambient lighting); (3) to understand the health economic potential of Lifelight; and (4) to compare the patients’ experience of current contact-based methods for measuring VS and Lifelight and to evaluate the patients’ acceptance and appetite for Lifelight.'],\n",
       "  'METHODS': ['Methods',\n",
       "   'Ethics Approval',\n",
       "   'The VISION-MD protocol was approved by the South Berkshire Research Ethics Committee on November 24, 2020 (20/SC/0432).',\n",
       "   'Before the study started, the initial study protocol was approved by Health Research Authority (HRA) Wales on January 18, 2021 (IRAS 289242).',\n",
       "   'HRA Wales has also approved subsequent protocol amendments.',\n",
       "   'Participants and Recruitment',\n",
       "   'Participants are being recruited from multiple venues across Portsmouth Hospitals University NHS Trust, Barts Health NHS Trust, London, and from the community in London and Portsmouth (eg, religious places, community centers, offices, patient events, waiting areas in general practices, academic institutions, sports facilities, and care homes).',\n",
       "   'The participants are inpatients, outpatients, friends and family of patients, visitors, hospital staff members, and the general public.',\n",
       "   'The study staff approach inpatients during their hospital stay and outpatients while waiting for appointments.',\n",
       "   'For adults lacking capacity (eg, critically ill patients), the next of kin are contacted by telephone.',\n",
       "   'In addition, ethics-approved advertising materials are disseminated to Trust staff by email and in meetings, and posters are displayed in staff, patient, and public areas.',\n",
       "   'Inclusion criteria include individuals aged 16 years and older, sufficiently conversant in the English language, and able and willing to comply with all study requirements and to provide informed consent (either themselves or empowered by law to provide it).',\n",
       "   'There are no exclusion criteria.',\n",
       "   'Eligible potential participants are provided with an ethics-approved participant information sheet explaining the study aims, what is involved, and the requirements for participation; members of the team are available to discuss the study with interested individuals.',\n",
       "   'Informed consent is obtained electronically using Research Electronic Data Capture (REDCap), a secure National Health Service (NHS)–compliant web-based platform for survey and database management (project-redcap-org).',\n",
       "   'For adults lacking capacity, informed consent is obtained from a nominated consultee (next of kin or a doctor not involved in the study).',\n",
       "   'Participation in the study is entirely voluntary, refusal to participate does not incur a penalty or loss of medical benefits, and participants may withdraw from the study at any time.',\n",
       "   'Recruitment started in May 2021 but was compromised by restrictions implemented during the COVID-19 pandemic to limit access to hospitals by the general public.',\n",
       "   'Protocol amendments were made to increase community recruitment in light of these issues.',\n",
       "   'Target recruitment is approximately 1950 participants to generate measurements for use in the initial training data set and for performance testing.',\n",
       "   'However, the final sample size will depend on the incremental improvement in accuracy of the Lifelight algorithm and therefore cannot be predicted (see Sample Size section).',\n",
       "   'The study will continue until the accuracy of Lifelight for measuring VS is sufficient for various clinical use cases.',\n",
       "   'Study Procedures',\n",
       "   'Premeasurement observations',\n",
       "   'A brief set of demographic and medical history questions are asked, limited to the presence or absence of conditions that might affect skin perfusion and pigmentation and cardiovascular processes and any prescription medicines for these conditions.',\n",
       "   'The study staff record a set of premeasurement observations and the presence or absence of sweat on the participant’s face; any facial hair on the cheeks; tattoos, jewelry, birthmarks, scars, or other features on the face; the use of foundation or concealer; and the position of the participant (seated, prone, supine, or lying on one side).',\n",
       "   'Subprotocol assignment',\n",
       "   'Patients with capacity are recruited into 1 of 3 subprotocols depending on premeasurement observations ( Table 1 ).',\n",
       "   'Participants may also be recruited to a subprotocol based on their skin tone (Fitzpatrick Skin Type scale [ 18 ]) to meet prespecified targets.',\n",
       "   'Adults who lack capacity are recruited into subprotocol 4.',\n",
       "   'Participants may be involved in up to 10 study sessions, allowing the collection of longitudinal data.',\n",
       "   'The subprotocol approach allows the study personnel to focus on fewer tasks.',\n",
       "   'It also enables high-quality data collection while avoiding the collection of data that would not be used to meet study objectives, consistent with the General Data Protection Regulation for data minimization.',\n",
       "   'VS measurement',\n",
       "   'The study staff ensure that participants have been at rest for at least 10\\xa0minutes before VS measurement starts and that they have not consumed any food or drink in the previous 30\\xa0minutes (other than intravenous fluids or nasogastric feeding).',\n",
       "   'In each study session, VS is measured as per the subprotocol using the standard-of-care equipment while simultaneously capturing a video of the participant’s face using the Data Collect app running on a tablet (standard iPad 9.7, 2018) positioned approximately 1\\xa0m away and angled toward the participant’s face.',\n",
       "   'Controls and instructions on the device start and stop the 60-second video recording.',\n",
       "   'Background luminosity is measured using a handheld lux meter.',\n",
       "   'The study staff have been briefed on the optimum Lifelight measurement conditions.',\n",
       "   'Recordings are repeated once or twice, as set out in Table 1 .',\n",
       "   'The app does not return any measurements to the user or participant.',\n",
       "   'VS measurements are taken and coordinated by 2 nurses, one of whom announces the start and finish of the recording period on the Data Collect app.',\n",
       "   'BP is measured using a standard clinical automatic sphygmomanometer with an appropriately sized cuff (width at least two-thirds of upper arm length) on the participant’s nondominant upper arm (unless contraindicated) or via an arterial line if fitted.',\n",
       "   'BP is recorded at the start of the recording period.',\n",
       "   'A standard clinical finger clip sensor for the measurement of oxygen saturation and pulse rate is placed on a finger on the opposite side of the body to the sphygmomanometer.',\n",
       "   'Oxygen saturation and pulse rate are measured at 0, 30, and 60 seconds of the recording period and averaged.',\n",
       "   'Respiratory rate is determined manually by counting chest rises throughout the 60-second period.',\n",
       "   'The nurse may place their hand on the participant’s chest to increase the accuracy of manual counting but being mindful not to obscure the camera’s line of sight.',\n",
       "   'Each study session takes approximately 30\\xa0minutes.',\n",
       "   'Once the measurements are completed, the study staff complete the postmeasurement observation questions relating to how much the participant moved, their position, whether they were wearing glasses, any hairstyle or other item (eg, face covering) that obscured any part of their face during the recording, and whether the software reported “face not found” at any point during the recording.',\n",
       "   'Patient Feedback',\n",
       "   'Equal proportions of participants in subprotocols 1-3 are being asked to complete a questionnaire related to VS measurement and their preferences.',\n",
       "   'The data are fully anonymized and recorded without any identifiable information (including participant ID code).',\n",
       "   'Clinical Feedback',\n",
       "   'A questionnaire is available to garner feedback on the technology from the clinical user’s point of view (ie, the nurses who take the VS measurements).',\n",
       "   'Questionnaire and interview data are fully anonymized and recorded without any identifiable information.',\n",
       "   'Health Economics Data Collection',\n",
       "   'The study also includes activities to obtain information and data to assess the cost-saving potential of Lifelight in different clinical settings, including as a tool to detect undiagnosed cardiovascular disease and to monitor symptoms.',\n",
       "   'The cost of BP monitoring equipment and its maintenance and calibration will also be determined.',\n",
       "   'Stopwatch observational studies are run to determine how long it takes to measure VS using standard-of-care equipment and Lifelight, starting from the time when the clinician decides to conduct a VS check and incorporating the time it takes to find the measuring equipment, roll up the patient’s sleeve, put on the devices, wait for the result, and put the equipment away.',\n",
       "   'This part of the study will involve approximately 20 participants.',\n",
       "   'Privacy and Data Collection',\n",
       "   'Each study participant is assigned a unique sequential ID; no identifiable data are stored.',\n",
       "   'All documents are stored securely and are only accessible by the study staff and authorized personnel.',\n",
       "   'The code linking the ID to the participant’s personal information is kept within the hospital study site and can only be accessed by the research team.',\n",
       "   'Full-resolution video data are uploaded during the study.',\n",
       "   'The consent form allows the participants to decide whether data can be shared as full-face video or with identifying features obscured.',\n",
       "   'Videos collected in the study constitute personal data, as it may be possible to identify participants, but are collected for research purposes only (not clinical care) and are processed within the legitimate interests of Xim Ltd. These data will be protected according to the General Data Protection Regulation.',\n",
       "   'Data Handling',\n",
       "   'For each reading, a high-quality video of the whole face is saved to the internal storage of the iPad in encrypted form.',\n",
       "   'Anonymized rPPG data (the average color of areas of the face) are saved directly and immediately sent to an NHS-compliant cloud server.',\n",
       "   'Subsequent analysis will be performed using the encrypted files, which are downloaded to a processing site, decrypted, and processed automatically (ie, without any person viewing the videos).',\n",
       "   'This procedure will result in anonymized aggregate data sets.',\n",
       "   'Decrypted files will subsequently be deleted from the processing site.',\n",
       "   'All protocol-required information besides video data is collected in an electronic case report form.',\n",
       "   'The REDCap electronic cloud is used to store and manage all consent and study data.',\n",
       "   'All data collected about study participants are kept strictly confidential.',\n",
       "   'Performance Targets',\n",
       "   'The accuracy of Lifelight using the training data generated in VISION-D was sufficient to support the certification of Lifelight as a class I CE medical device [ 15 ].',\n",
       "   'However, the accuracy needs to be improved further for use in routine clinical practice.',\n",
       "   'Table 2 lists the performance targets for Lifelight; training data collected during VISION-MD will support the progress toward these targets.',\n",
       "   'Sample Size',\n",
       "   'The sample size cannot be formally calculated because it depends on the incremental improvement in the accuracy of Lifelight achieved through machine learning using the training data generated in the study.',\n",
       "   'However, indicative sample sizes for the 4 subprotocols have been calculated by assessing the optimal data requirements to enable algorithm training toward the standards defined in Table 3 , balanced against the practicality of achieving the targets.',\n",
       "   'The split between training and testing data will be determined during the study according to the quality of the data collected.',\n",
       "   'The initial protocol anticipated data collection from about 8400 participants for training and a further 1000 for independent testing of accuracy, but the recruitment has been compromised by restrictions implemented during the COVID-19 pandemic.',\n",
       "   'However, the high-quality video recording (compared with VISION-D and VISION-V) supported a protocol amendment to reduce the recruitment to 1950 participants (see Results section), with the expectation that data from about 1700 will be used for training the algorithms and data from 250 used for testing.',\n",
       "   'The study management team is monitoring the progress of data collection and accuracy, and updates the study teams monthly.',\n",
       "   'The study will continue until the accuracy of Lifelight for measuring VS is sufficient for various clinical use cases.',\n",
       "   'As skin tone is expected to affect the accuracy of Lifelight, the aim is to recruit participants across the full Fitzpatrick skin tone scale (1-6).',\n",
       "   'To allow the impact of skin tone measurement accuracy to be determined with statistical robustness, the full data set will be sampled to create a subset for skin tone analyses in which the prevalence of the usually less prevalent skin tones is amplified.',\n",
       "   'This subset will contain 750-1000 measurements, with 15%-20% each from categories 1, 2 and 3, 4, and 5 and 6.',\n",
       "   'These measurements should be spread across the subprotocols as indicated in Table 3 .',\n",
       "   'Data Analysis',\n",
       "   'The training data will be used to further develop the signal extraction and processing methodology.',\n",
       "   'The test data will subsequently be used to determine the performance of Lifelight against the targets set out in Table 2 .',\n",
       "   'All statistical analyses will be performed using Microsoft Excel.',\n",
       "   'All analyses will be completed per protocol since there is no intention to treat.',\n",
       "   'There will be no imputation of missing or implausible data, and any missing, implausible, or problematic readings will be excluded from the analysis.',\n",
       "   'If the Lifelight software is unable to detect the participant’s face during the measurement period, this will be recorded in the electronic case report form, and the measurements will be deleted from the data set.'],\n",
       "  'TABLE': ['Table 1',\n",
       "   'Recruitment criteria and vital sign measurement in subprotocols 1-4.',\n",
       "   'Subprotocol',\n",
       "   'Recruitment criteria',\n",
       "   'Measurements',\n",
       "   'Measurements, n',\n",
       "   'PR a',\n",
       "   'BP b',\n",
       "   'RR c',\n",
       "   'SpO 2 d',\n",
       "   '1',\n",
       "   'Abnormal BP e',\n",
       "   '✓',\n",
       "   '✓',\n",
       "   '✓',\n",
       "   '3',\n",
       "   '2',\n",
       "   'Any participant',\n",
       "   '✓',\n",
       "   '✓',\n",
       "   '2',\n",
       "   '3',\n",
       "   'Expected to have low SpO 2 f',\n",
       "   '✓',\n",
       "   '2',\n",
       "   '4',\n",
       "   'Adults lacking capacity',\n",
       "   '✓',\n",
       "   '✓',\n",
       "   '✓',\n",
       "   '✓',\n",
       "   '3',\n",
       "   'a PR: pulse rate.',\n",
       "   'b BP: blood pressure.',\n",
       "   'c RR: respiratory rate.',\n",
       "   'd SpO 2 : oxygen saturation.',\n",
       "   'e Abnormal defined as systolic blood pressure <100 mm Hg or >140\\xa0mm Hg.',\n",
       "   'f Low SpO 2 (anticipated to be ≤95%).',\n",
       "   'Table 2',\n",
       "   'Performance (accuracy) targets for Lifelight.',\n",
       "   'Vital signs',\n",
       "   'Accuracy target',\n",
       "   'Basis for target',\n",
       "   'Blood pressure',\n",
       "   'SBP a can be measured with standard deviation ≤8\\xa0mm Hg British Hypertension Society Grade C for SBP measurement',\n",
       "   'ISO81060-2 b for blood pressure cuffs [ 19 ]',\n",
       "   'Pulse rate',\n",
       "   'Root mean square error of ≤3\\xa0beats per minute',\n",
       "   'Most common accuracy of CE c -marked commercially available devices',\n",
       "   'Respiratory rate',\n",
       "   'Maximum error tolerance of 5 breaths per minute',\n",
       "   'Accuracy of Philips Health watch, a CE-marked contact-based photoplethysmography device',\n",
       "   'Oxygen saturation',\n",
       "   'Maximum error tolerance of 4%',\n",
       "   'ISO80601-2-61 standard for pulse oximeters [ 20 ]',\n",
       "   'a SBP: systolic blood pressure.',\n",
       "   'b ISO: International Organization for Standardization.',\n",
       "   'c CE: Conformité Européenne.',\n",
       "   'Table 3',\n",
       "   'Indicative sample size targets.',\n",
       "   'Subprotocol',\n",
       "   'Indicative sample size, n a',\n",
       "   'Characteristics',\n",
       "   'Participants with skin tone categories 1, 4, 5, and 6',\n",
       "   '1',\n",
       "   '1500',\n",
       "   'Roughly 100 participants will be recruited with SOC b -determined SBP c in each 10\\xa0mm Hg increment from <90 mm Hg to >200\\xa0mm Hg (ie, <90 mm Hg; 90-99 mm Hg; 100-109 mm Hg, etc) d',\n",
       "   'Ideally ≥4 in each SBP band',\n",
       "   '2',\n",
       "   '375',\n",
       "   'N/A e',\n",
       "   'Ideally ≥10 in each SBP band',\n",
       "   '3',\n",
       "   '35',\n",
       "   'Approximately 33% with SOC-measured oxygen saturation <88%, 88%-92%, and 93%-95%',\n",
       "   'Ideally, each band will include participants with each skin tone',\n",
       "   '4',\n",
       "   'No specific target; likely to be a small proportion',\n",
       "   'N/A',\n",
       "   'N/A',\n",
       "   'a Participants in subprotocol 4 (ie, those without the capacity to provide informed consent) are likely to have vital sign values outside of the normal range and will contribute to all subprotocol targets.',\n",
       "   'Only the first study session per participant contributes to the sample size.',\n",
       "   'b SOC: standard of care.',\n",
       "   'c SBP: systolic blood pressure.',\n",
       "   'd Can include participants with SBP measured from an arterial line.',\n",
       "   'e N/A: not applicable.'],\n",
       "  'RESULTS': ['Results',\n",
       "   'The prototype Lifelight technology has been in development since 2016.',\n",
       "   'The recruitment of participants for VISION-MD started in May 2021 but was compromised by the restrictions implemented to manage the COVID-19 pandemic, including restricting hospital access to the general public.',\n",
       "   'Protocol amendments were thus made to enhance community recruitment, including the use of incentives such as chocolates or gift cards.',\n",
       "   'In addition, the higher-resolution video recording (compared with the earlier VISION studies) supported reduction of the recruitment target to 1950, which is expected to yield sufficient high-quality measurements for machine learning and subsequent testing (reflected in a further protocol amendment).',\n",
       "   'An additional amendment allowed the measurement of BP and pulse rate using devices other than the standard-of-care Welch Allyn devices (and indicated in the electronic case report form), as not all participating centers had the originally specified equipment.',\n",
       "   'Data for analysis will become available from September 2022, and the algorithms will be continuously refined to improve clinical accuracy.',\n",
       "   'We anticipate that the final analyses to determine the performance of Lifelight against the targets set out in Table 2 will be complete in early 2023.'],\n",
       "  'DISCUSS': ['Discussion',\n",
       "   'The VISION-MD study is expected to provide sufficient high-quality data from a wide range of healthy volunteers and patients (including critically ill patients) to further develop the accuracy of the software for estimating VS in clinical and community settings.',\n",
       "   'While the VISION-V and -D studies demonstrated the potential value of Lifelight in the contactless measurement of VS and supported class I CE certification [ 15 ], further refinement of data collection and analysis methods is needed—particularly VS measurements outside the normal healthy range—to develop the algorithms for clinical use.',\n",
       "   'The high-quality videos collected in the VISION-MD studies will be instrumental in training the algorithms being developed for data processing.',\n",
       "   'A proportion of the data collected will be retained for testing the performance of Lifelight in estimating VS compared with the standard of care.',\n",
       "   'The study findings will be published in high-impact peer-reviewed scientific journals and presented at international cardiology, respiratory, and medical device conferences.'],\n",
       "  'ABBR': ['Abbreviations',\n",
       "   'BP',\n",
       "   'blood pressure',\n",
       "   'CE',\n",
       "   'Conformité Européenne',\n",
       "   'HRA',\n",
       "   'Health Research Authority',\n",
       "   'NHS',\n",
       "   'National Health Service',\n",
       "   'PPG',\n",
       "   'photoplethysmography',\n",
       "   'REDCap',\n",
       "   'Research Electronic Data Capture',\n",
       "   'rPPG',\n",
       "   'remote photoplethysmography',\n",
       "   'VS',\n",
       "   'vital signs',\n",
       "   'VISION-D',\n",
       "   'Measurement of Vital Signs by Lifelight Software in Comparison to the Standard of Care–Development',\n",
       "   'VISION-V',\n",
       "   'Measurement of Vital Signs by Lifelight Software in Comparison to the Standard of Care–Validation',\n",
       "   'VISION-MD',\n",
       "   'Measurement of Vital Signs by Lifelight Software in Comparison to the Standard of Care–Multisite Development'],\n",
       "  'REF': ['1 Buist MD Jarmolowski E Burton PR Bernard SA Waxman BP Anderson J Recognising clinical instability in hospital patients before cardiac arrest or unplanned admission to intensive care.',\n",
       "   'A pilot study in a tertiary-care hospital Med J Aust 1999 07 05 171 1 22 25 10.5694/j.1326-5377.1999.tb123492.x 10451667 10451667 2 Hands C Reid E Meredith P Smith GB Prytherch DR Schmidt PE Featherstone PI Patterns in the recording of vital signs and early warning scores: compliance with a clinical escalation protocol BMJ Qual Saf 2013 09 22 9 719 726 10.1136/bmjqs-2013-001954 23603474 bmjqs-2013-001954 3 van Leuvan CH Mitchell I Missed opportunities?',\n",
       "   \"An observational study of vital sign measurements Crit Care Resusc 2008 06 10 2 111 115 18522524 18522524 4 Ludikhuize J Smorenburg SM de Rooij SE de Jonge E Identification of deteriorating patients on general wards; measurement of vital parameters and potential effectiveness of the Modified Early Warning Score J Crit Care 2012 08 27 4 424.e7 13 10.1016/j.jcrc.2012.01.003 22341727 S0883-9441(12)00016-0 5 Flacco ME Manzoli L Bucci M Capasso L Comparcini D Simonetti V Gualano MR Nocciolini M D'Amario C Cicolini G Uneven accuracy of home blood pressure measurement: a multicentric survey J Clin Hypertens (Greenwich) 2015 08 17 8 638 643 10.1111/jch.12552 10.1111/jch.12552 25880129 25880129 6 Kamal AA Harness JB Irving G Mearns AJ Skin photoplethysmography—a review Comput Methods Programs Biomed 1989 04 28 4 257 269 10.1016/0169-2607(89)90159-4 2649304 0169-2607(89)90159-4 2649304 7 Johansson A Oberg PA Sedin G Monitoring of heart and respiratory rates in newborn infants using a new photoplethysmographic technique J Clin Monit Comput 1999 12 15 7-8 461 467 10.1023/a:1009912831366 12578044 12578044 8 Poh M Poh YC Validation of a standalone smartphone application for measuring heart rate using imaging photoplethysmography Telemed J E Health 2017 08 23 8 678 683 10.1089/tmj.2016.0230 28140834 28140834 9 Aoyagi T Miyasaka K Pulse oximetry: its invention, contribution to medicine, and future tasks Anesth Analg 2002 01 94 1 Suppl S1 3 11900029 10 Elgendi M Fletcher R Liang Y Howard N Lovell NH Abbott D Lim K Ward R The use of photoplethysmography for assessing hypertension NPJ Digit Med 2019 2 60 10.1038/s41746-019-0136-7 10.1038/s41746-019-0136-7 31388564 136 31388564 11 Radha M de Groot K Rajani N Wong CCP Kobold N Vos V Fonseca P Mastellos N Wark PA Velthoven N Haakma R Aarts RM Estimating blood pressure trends and the nocturnal dip from photoplethysmography Physiol Meas 2019 02 26 40 2 025006 10.1088/1361-6579/ab030e 30699397 30699397 12 Nilsson L Johansson A Kalman S Monitoring of respiratory rate in postoperative care using a new photoplethysmographic technique J Clin Monit Comput 2000 16 4 309 315 10.1023/a:1011424732717 12578078 12578078 13 Sun Y Yang Y Wu B Huang P Cheng S Wu B Chen C Contactless facial video recording with deep learning models for the detection of atrial fibrillation Sci Rep 2022 01 07 12 1 281 10.1038/s41598-021-03453-y 10.1038/s41598-021-03453-y 34996908 10.1038/s41598-021-03453-y 34996908 14 Heiden E Jones T Measurement of vital signs using Lifelight® Remote Photoplethysmography: results of the VISION-D and VISION-V observational studies JMIR Form Res 2022 6 11 e36340 10.2196/36340 36374541 15 Medtech innovation briefing MIB213: Lifelight First for monitoring vital signs 2020 National Institute for Health and Care Excellence 2022 2022-10-11 https://www.nice.org.uk/advice/mib213/chapter/The-technology 16 Kwon S Kim J Lee D Park K ROI analysis for remote photoplethysmography on facial video Annu Int Conf IEEE Eng Med Biol Soc 2015 08 4938 4941 10.1109/EMBC.2015.7319499 26737399 26737399 17 Kashima H Ikemura T Hayashi N Regional differences in facial skin blood flow responses to the cold pressor and static handgrip tests Eur J Appl Physiol 2013 04 113 4 1035 1041 10.1007/s00421-012-2522-6 23064980 23064980 18 Colvonen PJ Response to: investigating sources of inaccuracy in wearable optical heart rate sensors NPJ Digit Med 2021 02 26 4 1 38 10.1038/s41746-021-00408-5 10.1038/s41746-021-00408-5 33637822 10.1038/s41746-021-00408-5 33637822 19 ISO 81060-2+A1: non-invasive sphygmomanometers— part 2: clinical investigation of intermittent automated measurement type ISO 2019 2022-10-11 https://www.iso.org/standard/73339.html 20 ISO 80601-2-61: medical electrical equipment— part 2-61: particular requirements for basic safety and essential performance of pulse oximeter equipment ISO 2019 2022-10-11 https://www.iso.org/standard/67963.html\"],\n",
       "  'ack': ['The VISION-MD protocol was codeveloped by Barts Biomedical Research Centre, Portsmouth Hospitals University NHS Trust, Mind over Matter Medtech, and Xim Ltd. This report is an independent research funded by the National Institute for Health Research (Artificial Intelligence, Developing Lifelight: A contactless vital signs monitor for CVD screening, AI_AWARD02031) and NHSX.',\n",
       "   'The views expressed in this publication are those of the authors and not necessarily those of the National Institute for Health Research, NHSX, or the Department of Health and Social Care.',\n",
       "   'Medical writing support was provided by Helen Barham, PhD (The Text Doctor), funded by Xim Ltd.',\n",
       "   'The contributors associated with Lifelight Trials Group are as follows: Sharon Allard, Dr Mark Lyons-Amos, Bethany Armstead, Rosalynn Austin, Rebecca Baker, Dr Michelle Baker Moffat, Armida Balawon, Debbi Barnes, Sonia Baryschpolec, Sean Beech, Selina Begum, Lauren Bell, Helen Blackman, Marie Broadway, Kate Burrows, Philippa Copnall, Zoe Daly, Joanne Dash, Mini David, Teresa Day, Jacqueline Denham, Rodrigo Dias, Alison Dimmer, Gemma Dixon, Tracey Dobson, Catherine Edwards, Carole Fogg, Dr Jim Forrer, Francis Galera, Zoe Garner, Andrew Gribbin, Elizabeth Hawes, Serena Howe, Karen Hudson, Amanda Hungate, Victoria Hunter, Jo Kerr, Adam Kiddle, Arjun Kumar, Shanqin Liu, Beverley Longhurst, Sharon McCready, Shoid Miah, Maria Moon, Kirsty Parker, Gina Pelletier, Connie Petronzio, David Petronzio, Michelle Pople, Benildo Jr Quiros, Deidre Rodgers, Dr Mike Sadler, Kerrie Scott, Josh Sephton, Samantha Smith, Bruce Stanley, Nina Szarazova, Nick Thorne, Monika Thwaites, Sarah Tronk, Catherine Tuffrey, Marcus Tuke, Charlotte Turner, James Turner, Lewis Valaitis, Dr Lieke van Putten, Lyn Vinall, Marie White, Melanie Willcox, Jonathon Winter, Carole Wragg, Kim Wren.']}}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_full_text(ss[191])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "06f31a47-ce68-46fe-9fca-7e501b74fa14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<article open-status=\"O\" xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" dtd-version=\"1.3\" xml:lang=\"en\" article-type=\"research-article\"><?DTDIdentifier.IdentifierValue -//NLM//DTD Journal Publishing DTD v2.0 20040830//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName journalpublishing.dtd?><?SourceDTD.Version 2.0?><?ConverterInfo.XSLTName nlm2jats3.xsl?><?ConverterInfo.Version 1?><?properties open_access?><processing-meta base-tagset=\"archiving\" mathml-version=\"3.0\" table-model=\"xhtml\" tagset-family=\"jats\"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type=\"nlm-ta\">JMIR Res Protoc</journal-id><journal-id journal-id-type=\"iso-abbrev\">JMIR Res Protoc</journal-id><journal-id journal-id-type=\"publisher-id\">ResProt</journal-id><journal-title-group><journal-title>JMIR Research Protocols</journal-title></journal-title-group><issn pub-type=\"epub\">1929-0748</issn><publisher><publisher-name>JMIR Publications</publisher-name><publisher-loc>Toronto, Canada</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type=\"pmcid\">9878372</article-id><article-id pub-id-type=\"publisher-id\">v12i1e41533</article-id><article-id pub-id-type=\"pmid\">36630158</article-id><article-id pub-id-type=\"doi\">10.2196/41533</article-id><article-categories><subj-group subj-group-type=\"heading\"><subject>Protocol</subject></subj-group><subj-group subj-group-type=\"article-type\"><subject>Protocol</subject></subj-group></article-categories><title-group><article-title>Measurement of Vital Signs by Lifelight Software in Comparison to Standard of Care Multisite Development (VISION-MD): Protocol for an Observational Study</article-title></title-group><contrib-group><contrib contrib-type=\"editor\"><name><surname>Leung</surname><given-names>Tiffany</given-names></name></contrib></contrib-group><contrib-group><contrib id=\"contrib1\" contrib-type=\"author\" equal-contrib=\"yes\"><name><surname>Wiffen</surname><given-names>Laura</given-names></name><degrees>BMBS, MRCP</degrees><on-behalf-of>Lifelight Trials Group</on-behalf-of><xref rid=\"aff1\" ref-type=\"aff\">1</xref><contrib-id contrib-id-type=\"orcid\">https://orcid.org/0000-0003-3688-7662</contrib-id></contrib><contrib id=\"contrib2\" contrib-type=\"author\" equal-contrib=\"yes\"><name><surname>Brown</surname><given-names>Thomas</given-names></name><degrees>MBChB, PhD</degrees><xref rid=\"aff1\" ref-type=\"aff\">1</xref><contrib-id contrib-id-type=\"orcid\">https://orcid.org/0000-0001-7336-4719</contrib-id></contrib><contrib id=\"contrib3\" contrib-type=\"author\"><name><surname>Brogaard Maczka</surname><given-names>Annika</given-names></name><degrees>BSc</degrees><xref rid=\"aff2\" ref-type=\"aff\">2</xref><contrib-id contrib-id-type=\"orcid\">https://orcid.org/0000-0002-6718-2537</contrib-id></contrib><contrib id=\"contrib4\" contrib-type=\"author\" corresp=\"yes\"><name><surname>Kapoor</surname><given-names>Melissa</given-names></name><degrees>BSc, PhD</degrees><contrib-id contrib-id-type=\"orcid\">https://orcid.org/0000-0002-1811-2401</contrib-id><xref rid=\"aff2\" ref-type=\"aff\">2</xref><address><institution>Mind Over Matter MedTech Ltd</institution><addr-line>Kemp House</addr-line><addr-line>160 City Road</addr-line><addr-line>London, EC1V 2NX</addr-line><country>United Kingdom</country><phone>44 7881 927063</phone><email>melissa@mind-medtech.com</email></address></contrib><contrib id=\"contrib5\" contrib-type=\"author\"><name><surname>Pearce</surname><given-names>Laurence</given-names></name><degrees>BSc, MBA</degrees><xref rid=\"aff3\" ref-type=\"aff\">3</xref><contrib-id contrib-id-type=\"orcid\">https://orcid.org/0000-0001-7817-6426</contrib-id></contrib><contrib id=\"contrib6\" contrib-type=\"author\"><name><surname>Chauhan</surname><given-names>Milan</given-names></name><degrees>BSc</degrees><xref rid=\"aff1\" ref-type=\"aff\">1</xref><contrib-id contrib-id-type=\"orcid\">https://orcid.org/0000-0001-6242-4587</contrib-id></contrib><contrib id=\"contrib7\" contrib-type=\"author\"><name><surname>Chauhan</surname><given-names>Anoop J</given-names></name><degrees>MBChB, MBE, PhD</degrees><xref rid=\"aff1\" ref-type=\"aff\">1</xref><xref rid=\"aff4\" ref-type=\"aff\">4</xref><contrib-id contrib-id-type=\"orcid\">https://orcid.org/0000-0003-4044-6114</contrib-id></contrib><contrib id=\"contrib8\" contrib-type=\"author\"><name><surname>Saxena</surname><given-names>Manish</given-names></name><degrees>MBBS, MSc</degrees><xref rid=\"aff5\" ref-type=\"aff\">5</xref><contrib-id contrib-id-type=\"orcid\">https://orcid.org/0000-0001-9964-2692</contrib-id></contrib><contrib id=\"contrib9\" contrib-type=\"author\"><collab>Lifelight Trials Group</collab><xref rid=\"aff6\" ref-type=\"aff\">6</xref></contrib></contrib-group><aff id=\"aff1\">\\n<label>1</label>\\n<institution>Department of Research and Innovation</institution>\\n<institution>Queen Alexandra Hospital</institution>\\n<institution>Portsmouth Hospitals University NHS Trust</institution>\\n<addr-line>Portsmouth</addr-line>\\n<country>United Kingdom</country>\\n</aff><aff id=\"aff2\">\\n<label>2</label>\\n<institution>Mind Over Matter MedTech Ltd</institution>\\n<addr-line>London</addr-line>\\n<country>United Kingdom</country>\\n</aff><aff id=\"aff3\">\\n<label>3</label>\\n<institution>Xim Ltd</institution>\\n<addr-line>Southamptom</addr-line>\\n<country>United Kingdom</country>\\n</aff><aff id=\"aff4\">\\n<label>4</label>\\n<institution>Faculty of Science &#x00026; Health</institution>\\n<institution>University of Portsmouth</institution>\\n<institution>University Learning Centre</institution>\\n<addr-line>Portsmouth</addr-line>\\n<country>United Kingdom</country>\\n</aff><aff id=\"aff5\">\\n<label>5</label>\\n<institution>National Institute for Health Research</institution>\\n<institution>Barts Biomedical Research Centre</institution>\\n<addr-line>London</addr-line>\\n<country>United Kingdom</country>\\n</aff><aff id=\"aff6\">\\n<label>6</label>\\n<institution>See Acknowledgments</institution>\\n<addr-line>London</addr-line>\\n<country>United Kingdom</country>\\n</aff><author-notes><corresp>Corresponding Author: Melissa Kapoor <email>melissa@mind-medtech.com</email></corresp></author-notes><pub-date pub-type=\"collection\"><year>2023</year></pub-date><pub-date pub-type=\"epub\"><day>11</day><month>1</month><year>2023</year></pub-date><volume>12</volume><elocation-id>e41533</elocation-id><history><date date-type=\"received\"><day>29</day><month>7</month><year>2022</year></date><date date-type=\"rev-request\"><day>10</day><month>8</month><year>2022</year></date><date date-type=\"rev-recd\"><day>3</day><month>9</month><year>2022</year></date><date date-type=\"accepted\"><day>6</day><month>9</month><year>2022</year></date></history><permissions><copyright-statement>&#x000a9;Laura Wiffen, Thomas Brown, Annika Brogaard Maczka, Melissa Kapoor, Laurence Pearce, Milan Chauhan, Anoop J Chauhan, Manish Saxena, Lifelight Trials Group. Originally published in JMIR Research Protocols (https://www.researchprotocols.org), 11.01.2023.</copyright-statement><copyright-year>2023</copyright-year><license><ali:license_ref xmlns:ali=\"http://www.niso.org/schemas/ali/1.0/\" specific-use=\"textmining\" content-type=\"ccbylicense\">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (<ext-link xlink:href=\"https://creativecommons.org/licenses/by/4.0/\" ext-link-type=\"uri\">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work, first published in JMIR Research Protocols, is properly cited. The complete bibliographic information, a link to the original publication on <ext-link xlink:href=\"https://www.researchprotocols.org\" ext-link-type=\"uri\">https://www.researchprotocols.org</ext-link>, as well as this copyright and license information must be included.</license-p></license></permissions><self-uri xlink:href=\"https://www.researchprotocols.org/2023/1/e41533\"/><abstract><sec sec-type=\"background\"><title>Background</title><p>Measuring vital signs (VS) is an important aspect of clinical care but is time-consuming and requires multiple pieces of equipment and trained staff. Interest in the contactless measurement of VS has grown since the COVID-19 pandemic, including in nonclinical situations. Lifelight is an app being developed as a medical device for the contactless measurement of VS using remote photoplethysmography (rPPG) via the camera on smart devices. The VISION-D (Measurement of Vital Signs by Lifelight Software in Comparison to the Standard of Care&#x02014;Development) and VISION-V (Validation) studies demonstrated the accuracy of Lifelight compared with standard-of-care measurement of blood pressure, pulse rate, and respiratory rate, supporting the certification of Lifelight as a class I Conformit&#x000e9; Europ&#x000e9;enne (CE) medical device.</p></sec><sec sec-type=\"objective\"><title>Objective</title><p>To support further development of the Lifelight app, the observational VISION Multisite Development (VISION-MD) study is collecting high-quality data from a broad range of patients, including those with VS measurements outside the normal healthy range and patients who are critically ill.</p></sec><sec sec-type=\"methods\"><title>Methods</title><p>The study is recruiting adults (aged &#x02265;16 years) who are inpatients (some critically ill), outpatients, and healthy volunteers, aiming to cover a broad range of normal and clinically relevant VS values; there are no exclusion criteria. High-resolution 60-second videos of the face are recorded by the Lifelight app while simultaneously measuring VS using standard-of-care methods (automated sphygmomanometer for blood pressure; finger clip sensor for pulse rate and oxygen saturation; manual counting of respiratory rate). Feedback from patients and nurses who use Lifelight is collected via a questionnaire. Data to estimate the cost-effectiveness of Lifelight compared with standard-of-care VS measurement are also being collected. A new method for rPPG signal processing is currently being developed, based on the identification of small areas of high-quality signals in each individual. Anticipated recruitment is 1950 participants, with the expectation that data from approximately 1700 will be used for software development. Data from 250 participants will be retained to test the performance of Lifelight against predefined performance targets.</p></sec><sec sec-type=\"results\"><title>Results</title><p>Recruitment began in May 2021 but was hindered by the restrictions instigated during the COVID-19 pandemic. The development of data processing methodology is in progress. The data for analysis will become available from September 2022, and the algorithms will be refined continuously to improve clinical accuracy. The performance of Lifelight compared with that of the standard-of-care measurement of VS will then be tested. Recruitment will resume if further data are required. The analyses are expected to be completed in early 2023.</p></sec><sec sec-type=\"conclusions\"><title>Conclusions</title><p>This study will support the refinement of data collection and processing toward the development of a robust app that is suitable for routine clinical use.</p></sec><sec sec-type=\"Trial Registration\"><title>Trial Registration</title><p>ClinicalTrials.gov NCT04763746; https://clinicaltrials.gov/ct2/show/NCT04763746</p></sec><sec sec-type=\"registered-report\"><title>International Registered Report Identifier (IRRID)</title><p>DERR1-10.2196/41533</p></sec></abstract><kwd-group><kwd>general practice</kwd><kwd>vital signs/methods</kwd><kwd>vital signs/standards</kwd><kwd>photoplethysmography</kwd><kwd>remote photoplethysmography</kwd><kwd>rPPG</kwd><kwd>Lifelight</kwd><kwd>contactless</kwd><kwd>software</kwd></kwd-group><custom-meta-group><custom-meta><meta-name>ext-peer-rev</meta-name><meta-value>This paper was peer reviewed by the Artificial Intelligence in Health and Care Award - National institute for Health and Care Research (NIHR) - Department of Health and Social Care (London, United Kingdom).</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec sec-type=\"introduction\"><title>Introduction</title><p>The measurement of vital signs (VS) provides important information about a patient\\'s health and, importantly, a change in VS may herald a deterioration in health [<xref rid=\"ref1\" ref-type=\"bibr\">1</xref>]. Despite the importance of VS to inform clinical decision-making, the accuracy and timeliness of measurement are in need of improvement [<xref rid=\"ref2\" ref-type=\"bibr\">2</xref>-<xref rid=\"ref4\" ref-type=\"bibr\">4</xref>]. However, the measurement of VS requires using multiple pieces of equipment that need to be calibrated regularly and is time-consuming. It may also be uncomfortable and stressful for patients, potentially compromising the utility of the information obtained. Standard-of-care medical equipment is not suitable for patients who require regular measurement of VS in the home or community setting to monitor long-term health conditions because of cost, the complexity of the measuring processes, and the need for calibration of equipment. A study of 725 patients reported that while 53% followed at least 10 of the recommended steps necessary for accurate blood pressure (BP) measurement at home, only 1% followed all 15 recommendations [<xref rid=\"ref5\" ref-type=\"bibr\">5</xref>]. Thus, home measurement of VS is important&#x02014;and respiratory rate and pulse rate in particular&#x02014;but requires several pieces of equipment (BP monitor and pulse oximeter) and for patients to be educated in best practices. The COVID-19 pandemic highlighted the need for remote or contactless VS measurement to reduce the risk of infection, which can be operated by people without specific medical training. The shift away from face-to-face to digital consultations during the pandemic also points to the need for easy but accurate measurement of VS.</p><p>Photoplethysmography (PPG) is an optical technique based on the measurement of the light reflected from the skin surface, which changes due to volumetric changes in the facial blood vessels; small variations in perfusion provide valuable information about the cardiovascular system [<xref rid=\"ref6\" ref-type=\"bibr\">6</xref>]. PPG has been used to measure pulse rate [<xref rid=\"ref7\" ref-type=\"bibr\">7</xref>,<xref rid=\"ref8\" ref-type=\"bibr\">8</xref>], oxygen saturation [<xref rid=\"ref9\" ref-type=\"bibr\">9</xref>], BP [<xref rid=\"ref10\" ref-type=\"bibr\">10</xref>,<xref rid=\"ref11\" ref-type=\"bibr\">11</xref>], and respiratory rate [<xref rid=\"ref7\" ref-type=\"bibr\">7</xref>,<xref rid=\"ref12\" ref-type=\"bibr\">12</xref>] and to detect atrial fibrillation [<xref rid=\"ref13\" ref-type=\"bibr\">13</xref>].</p><p>Lifelight (Xim Ltd) is an app being developed for the contactless measurement of VS using remote PPG (rPPG) via the camera on smart devices such as phones and tablets. The app captures the average color of the region of interest 30 times every second for 60 seconds and sends this as red, green, and blue values to the server for further processing. VS values are obtained from the green channel.</p><p>The VISION-D (Measurement of Vital Signs by Lifelight Software in Comparison to the Standard of Care-Development) study measured VS in 8585 patients and healthy volunteers simultaneously using Lifelight and standard-of-care methods. The data were used for machine learning to improve the accuracy of the Lifelight algorithms used to calculate VS. The smaller VISION-V (Measurement of Vital Signs by Lifelight Software in Comparison to the Standard of Care&#x02013;Validation) study demonstrated the accuracy of the Lifelight app compared with standard-of-care methods for measuring pulse rate, respiratory rate, and diastolic BP [<xref rid=\"ref14\" ref-type=\"bibr\">14</xref>], providing the basis for the current class I Conformit&#x000e9; Europ&#x000e9;enne (CE) registration [<xref rid=\"ref15\" ref-type=\"bibr\">15</xref>]. However, some of the methods used in the VISION-V study differed from the procedures described in the standard for BP measurement (ISO81060-2) because of the novel nature of the Lifelight technology. Furthermore, these early studies did not include participants with BP values across the full range likely to be encountered in clinical practice.</p><p>To further improve the accuracy of Lifelight, the Measurement of Vital Signs by Lifelight Software in Comparison to the Standard of Care&#x02013;Multisite Development (VISION-MD) study is collecting data from a wide range of outpatients, inpatients, and patients who are critically ill, and across the full range of skin tones, for use in machine learning. In VISION-D and VISION-V, full-face videos were recorded, but a high proportion of data were not usable. Thus, high-resolution full-face videos are being recorded to maximize the opportunity for machine learning. These data will also be used to evaluate alternative methods of defining the region of interest, as the full face includes areas that are not relevant (eg, areas covered by facial hair and areas that illicit a poor signal).</p><p>Given that only a small proportion of the raw video signal is relevant for rPPG measurement of VS (1%-2%), we are developing ways to enhance data collection and signal processing. Video recordings will be of higher resolution than those in the VISION-V and VISION-D studies, and data processing is focusing on the midface region (cheeks, nose, and top of the lip), rather than the whole face; these areas are computationally efficient for rPPG because of their large area and good-quality signal [<xref rid=\"ref16\" ref-type=\"bibr\">16</xref>] but are not likely to be affected by autoregulation of cerebral blood flow (which discounts the forehead) [<xref rid=\"ref17\" ref-type=\"bibr\">17</xref>]. We are also developing a method to identify small regions of interest in the midface in each participant where signal quality is the highest. This approach is expected to overcome some of the challenges of rPPG for routine clinical use, such as positioning of the participant relative to the light source.</p><p>VISION-MD (Clinicaltrials.gov NCT04763746) aims to advance the development and accuracy of the Lifelight app as a noninvasive and easy-to-use device to measure VS in hospitals and the community. The study will collect data from a broad range of patients to further develop the accuracy of Lifelight to a level sufficient for clinical applications, including screening and monitoring of cardiovascular disease. The initial data collected are being used for machine learning; later data will be used to test the accuracy of Lifelight compared with standard-of-care measurement of VS.</p><p>Thus, the primary objective of VISION-MD is to further develop the Lifelight algorithms across extensive clinical ranges, including critically ill patients and in patients with different skin tones. Secondary objectives are: (1) to improve and test the efficacy of Lifelight estimates for BP, pulse rate, respiratory rate, and oxygen saturation in multiple clinical settings (eg, critical care, outpatient clinics, and general hospital wards); (2) to evaluate the impact of variables on the accuracy of Lifelight VS measurements (eg, age, sex, temperature, health condition, medication, skin tone, and ambient lighting); (3) to understand the health economic potential of Lifelight; and (4) to compare the patients&#x02019; experience of current contact-based methods for measuring VS and Lifelight and to evaluate the patients&#x02019; acceptance and appetite for Lifelight.</p></sec><sec sec-type=\"methods\"><title>Methods</title><sec><title>Ethics Approval</title><p>The VISION-MD protocol was approved by the South Berkshire Research Ethics Committee on November 24, 2020 (20/SC/0432). Before the study started, the initial study protocol was approved by Health Research Authority (HRA) Wales on January 18, 2021 (IRAS 289242). HRA Wales has also approved subsequent protocol amendments.</p></sec><sec><title>Participants and Recruitment</title><p>Participants are being recruited from multiple venues across Portsmouth Hospitals University NHS Trust, Barts Health NHS Trust, London, and from the community in London and Portsmouth (eg, religious places, community centers, offices, patient events, waiting areas in general practices, academic institutions, sports facilities, and care homes). The participants are inpatients, outpatients, friends and family of patients, visitors, hospital staff members, and the general public. The study staff approach inpatients during their hospital stay and outpatients while waiting for appointments. For adults lacking capacity (eg, critically ill patients), the next of kin are contacted by telephone. In addition, ethics-approved advertising materials are disseminated to Trust staff by email and in meetings, and posters are displayed in staff, patient, and public areas.</p><p>Inclusion criteria include individuals aged 16 years and older, sufficiently conversant in the English language, and able and willing to comply with all study requirements and to provide informed consent (either themselves or empowered by law to provide it). There are no exclusion criteria. Eligible potential participants are provided with an ethics-approved participant information sheet explaining the study aims, what is involved, and the requirements for participation; members of the team are available to discuss the study with interested individuals. Informed consent is obtained electronically using Research Electronic Data Capture (REDCap), a secure National Health Service (NHS)&#x02013;compliant web-based platform for survey and database management (project-redcap-org). For adults lacking capacity, informed consent is obtained from a nominated consultee (next of kin or a doctor not involved in the study). Participation in the study is entirely voluntary, refusal to participate does not incur a penalty or loss of medical benefits, and participants may withdraw from the study at any time.</p><p>Recruitment started in May 2021 but was compromised by restrictions implemented during the COVID-19 pandemic to limit access to hospitals by the general public. Protocol amendments were made to increase community recruitment in light of these issues. Target recruitment is approximately 1950 participants to generate measurements for use in the initial training data set and for performance testing. However, the final sample size will depend on the incremental improvement in accuracy of the Lifelight algorithm and therefore cannot be predicted (see Sample Size section). The study will continue until the accuracy of Lifelight for measuring VS is sufficient for various clinical use cases.</p></sec><sec><title>Study Procedures</title><sec><title>Premeasurement observations</title><p>A brief set of demographic and medical history questions are asked, limited to the presence or absence of conditions that might affect skin perfusion and pigmentation and cardiovascular processes and any prescription medicines for these conditions. The study staff record a set of premeasurement observations and the presence or absence of sweat on the participant&#x02019;s face; any facial hair on the cheeks; tattoos, jewelry, birthmarks, scars, or other features on the face; the use of foundation or concealer; and the position of the participant (seated, prone, supine, or lying on one side).</p></sec><sec><title>Subprotocol assignment</title><p>Patients with capacity are recruited into 1 of 3 subprotocols depending on premeasurement observations (<xref rid=\"table1\" ref-type=\"table\">Table 1</xref>). Participants may also be recruited to a subprotocol based on their skin tone (Fitzpatrick Skin Type scale [<xref rid=\"ref18\" ref-type=\"bibr\">18</xref>]) to meet prespecified targets. Adults who lack capacity are recruited into subprotocol 4. Participants may be involved in up to 10 study sessions, allowing the collection of longitudinal data. The subprotocol approach allows the study personnel to focus on fewer tasks. It also enables high-quality data collection while avoiding the collection of data that would not be used to meet study objectives, consistent with the General Data Protection Regulation for data minimization.</p><table-wrap position=\"float\" id=\"table1\"><label>Table 1</label><caption><p>Recruitment criteria and vital sign measurement in subprotocols 1-4.</p></caption><table frame=\"hsides\" rules=\"groups\" width=\"1000\" cellpadding=\"5\" cellspacing=\"0\" border=\"1\"><col width=\"170\" span=\"1\"/><col width=\"360\" span=\"1\"/><col width=\"70\" span=\"1\"/><col width=\"70\" span=\"1\"/><col width=\"70\" span=\"1\"/><col width=\"70\" span=\"1\"/><col width=\"0\" span=\"1\"/><col width=\"190\" span=\"1\"/><thead><tr valign=\"top\"><td rowspan=\"1\" colspan=\"1\">Subprotocol</td><td rowspan=\"1\" colspan=\"1\">Recruitment criteria</td><td colspan=\"5\" rowspan=\"1\">Measurements</td><td rowspan=\"1\" colspan=\"1\">Measurements, n</td></tr><tr valign=\"top\"><td rowspan=\"1\" colspan=\"1\">\\n<break/>\\n</td><td rowspan=\"1\" colspan=\"1\">\\n<break/>\\n</td><td rowspan=\"1\" colspan=\"1\">PR<sup>a</sup></td><td rowspan=\"1\" colspan=\"1\">BP<sup>b</sup></td><td rowspan=\"1\" colspan=\"1\">RR<sup>c</sup></td><td rowspan=\"1\" colspan=\"1\">SpO<sub>2</sub><sup>d</sup></td><td colspan=\"2\" rowspan=\"1\">\\n<break/>\\n</td></tr></thead><tbody><tr valign=\"top\"><td rowspan=\"1\" colspan=\"1\">1</td><td rowspan=\"1\" colspan=\"1\">Abnormal BP<sup>e</sup></td><td rowspan=\"1\" colspan=\"1\">&#x02713;</td><td rowspan=\"1\" colspan=\"1\">&#x02713;</td><td rowspan=\"1\" colspan=\"1\">\\n<break/>\\n</td><td rowspan=\"1\" colspan=\"1\">&#x02713;</td><td colspan=\"2\" rowspan=\"1\">3</td></tr><tr valign=\"top\"><td rowspan=\"1\" colspan=\"1\">2</td><td rowspan=\"1\" colspan=\"1\">Any participant</td><td rowspan=\"1\" colspan=\"1\">\\n<break/>\\n</td><td rowspan=\"1\" colspan=\"1\">\\n<break/>\\n</td><td rowspan=\"1\" colspan=\"1\">&#x02713;</td><td rowspan=\"1\" colspan=\"1\">&#x02713;</td><td colspan=\"2\" rowspan=\"1\">2</td></tr><tr valign=\"top\"><td rowspan=\"1\" colspan=\"1\">3</td><td rowspan=\"1\" colspan=\"1\">Expected to have low SpO<sub>2</sub><sup>f</sup></td><td rowspan=\"1\" colspan=\"1\">\\n<break/>\\n</td><td rowspan=\"1\" colspan=\"1\">\\n<break/>\\n</td><td rowspan=\"1\" colspan=\"1\">\\n<break/>\\n</td><td rowspan=\"1\" colspan=\"1\">&#x02713;</td><td colspan=\"2\" rowspan=\"1\">2</td></tr><tr valign=\"top\"><td rowspan=\"1\" colspan=\"1\">4</td><td rowspan=\"1\" colspan=\"1\">Adults lacking capacity</td><td rowspan=\"1\" colspan=\"1\">&#x02713;</td><td rowspan=\"1\" colspan=\"1\">&#x02713;</td><td rowspan=\"1\" colspan=\"1\">&#x02713;</td><td rowspan=\"1\" colspan=\"1\">&#x02713;</td><td colspan=\"2\" rowspan=\"1\">3</td></tr></tbody></table><table-wrap-foot><fn id=\"table1fn1\"><p><sup>a</sup>PR: pulse rate.</p></fn><fn id=\"table1fn2\"><p><sup>b</sup>BP: blood pressure.</p></fn><fn id=\"table1fn3\"><p><sup>c</sup>RR: respiratory rate.</p></fn><fn id=\"table1fn4\"><p><sup>d</sup>SpO<sub>2</sub>: oxygen saturation.</p></fn><fn id=\"table1fn5\"><p><sup>e</sup>Abnormal defined as systolic blood pressure &#x0003c;100 mm Hg or &#x0003e;140&#x000a0;mm Hg.</p></fn><fn id=\"table1fn6\"><p><sup>f</sup>Low SpO<sub>2</sub> (anticipated to be &#x02264;95%).</p></fn></table-wrap-foot></table-wrap></sec><sec><title>VS measurement</title><p>The study staff ensure that participants have been at rest for at least 10&#x000a0;minutes before VS measurement starts and that they have not consumed any food or drink in the previous 30&#x000a0;minutes (other than intravenous fluids or nasogastric feeding). In each study session, VS is measured as per the subprotocol using the standard-of-care equipment while simultaneously capturing a video of the participant&#x02019;s face using the Data Collect app running on a tablet (standard iPad 9.7, 2018) positioned approximately 1&#x000a0;m away and angled toward the participant&#x02019;s face. Controls and instructions on the device start and stop the 60-second video recording. Background luminosity is measured using a handheld lux meter. The study staff have been briefed on the optimum Lifelight measurement conditions. Recordings are repeated once or twice, as set out in <xref rid=\"table1\" ref-type=\"table\">Table 1</xref>. The app does not return any measurements to the user or participant.</p><p>VS measurements are taken and coordinated by 2 nurses, one of whom announces the start and finish of the recording period on the Data Collect app. BP is measured using a standard clinical automatic sphygmomanometer with an appropriately sized cuff (width at least two-thirds of upper arm length) on the participant&#x02019;s nondominant upper arm (unless contraindicated) or via an arterial line if fitted. BP is recorded at the start of the recording period. A standard clinical finger clip sensor for the measurement of oxygen saturation and pulse rate is placed on a finger on the opposite side of the body to the sphygmomanometer. Oxygen saturation and pulse rate are measured at 0, 30, and 60 seconds of the recording period and averaged. Respiratory rate is determined manually by counting chest rises throughout the 60-second period. The nurse may place their hand on the participant&#x02019;s chest to increase the accuracy of manual counting but being mindful not to obscure the camera&#x02019;s line of sight.</p><p>Each study session takes approximately 30&#x000a0;minutes. Once the measurements are completed, the study staff complete the postmeasurement observation questions relating to how much the participant moved, their position, whether they were wearing glasses, any hairstyle or other item (eg, face covering) that obscured any part of their face during the recording, and whether the software reported &#x0201c;face not found&#x0201d; at any point during the recording.</p></sec><sec><title>Patient Feedback</title><p>Equal proportions of participants in subprotocols 1-3 are being asked to complete a questionnaire related to VS measurement and their preferences. The data are fully anonymized and recorded without any identifiable information (including participant ID code).</p></sec><sec><title>Clinical Feedback</title><p>A questionnaire is available to garner feedback on the technology from the clinical user&#x02019;s point of view (ie, the nurses who take the VS measurements). Questionnaire and interview data are fully anonymized and recorded without any identifiable information.</p></sec><sec><title>Health Economics Data Collection</title><p>The study also includes activities to obtain information and data to assess the cost-saving potential of Lifelight in different clinical settings, including as a tool to detect undiagnosed cardiovascular disease and to monitor symptoms. The cost of BP monitoring equipment and its maintenance and calibration will also be determined.</p><p>Stopwatch observational studies are run to determine how long it takes to measure VS using standard-of-care equipment and Lifelight, starting from the time when the clinician decides to conduct a VS check and incorporating the time it takes to find the measuring equipment, roll up the patient&#x02019;s sleeve, put on the devices, wait for the result, and put the equipment away. This part of the study will involve approximately 20 participants.</p></sec></sec><sec><title>Privacy and Data Collection</title><p>Each study participant is assigned a unique sequential ID; no identifiable data are stored. All documents are stored securely and are only accessible by the study staff and authorized personnel. The code linking the ID to the participant&#x02019;s personal information is kept within the hospital study site and can only be accessed by the research team.</p><p>Full-resolution video data are uploaded during the study. The consent form allows the participants to decide whether data can be shared as full-face video or with identifying features obscured.</p><p>Videos collected in the study constitute personal data, as it may be possible to identify participants, but are collected for research purposes only (not clinical care) and are processed within the legitimate interests of Xim Ltd. These data will be protected according to the General Data Protection Regulation.</p></sec><sec><title>Data Handling</title><p>For each reading, a high-quality video of the whole face is saved to the internal storage of the iPad in encrypted form. Anonymized rPPG data (the average color of areas of the face) are saved directly and immediately sent to an NHS-compliant cloud server.</p><p>Subsequent analysis will be performed using the encrypted files, which are downloaded to a processing site, decrypted, and processed automatically (ie, without any person viewing the videos). This procedure will result in anonymized aggregate data sets. Decrypted files will subsequently be deleted from the processing site.</p><p>All protocol-required information besides video data is collected in an electronic case report form. The REDCap electronic cloud is used to store and manage all consent and study data. All data collected about study participants are kept strictly confidential.</p></sec><sec><title>Performance Targets</title><p>The accuracy of Lifelight using the training data generated in VISION-D was sufficient to support the certification of Lifelight as a class I CE medical device [<xref rid=\"ref15\" ref-type=\"bibr\">15</xref>]. However, the accuracy needs to be improved further for use in routine clinical practice. <xref rid=\"table2\" ref-type=\"table\">Table 2</xref> lists the performance targets for Lifelight; training data collected during VISION-MD will support the progress toward these targets.</p><table-wrap position=\"float\" id=\"table2\"><label>Table 2</label><caption><p>Performance (accuracy) targets for Lifelight.</p></caption><table frame=\"hsides\" rules=\"groups\" width=\"1000\" cellpadding=\"5\" cellspacing=\"0\" border=\"1\"><col width=\"160\" span=\"1\"/><col width=\"440\" span=\"1\"/><col width=\"400\" span=\"1\"/><thead><tr valign=\"top\"><td rowspan=\"1\" colspan=\"1\">Vital signs</td><td rowspan=\"1\" colspan=\"1\">Accuracy target</td><td rowspan=\"1\" colspan=\"1\">Basis for target</td></tr></thead><tbody><tr valign=\"top\"><td rowspan=\"1\" colspan=\"1\">Blood pressure</td><td rowspan=\"1\" colspan=\"1\">\\n<list list-type=\"bullet\"><list-item><p>SBP<sup>a</sup> can be measured with standard deviation &#x02264;8&#x000a0;mm Hg</p></list-item><list-item><p>British Hypertension Society Grade C for SBP measurement</p></list-item></list>\\n</td><td rowspan=\"1\" colspan=\"1\">ISO81060-2<sup>b</sup> for blood pressure cuffs [<xref rid=\"ref19\" ref-type=\"bibr\">19</xref>]</td></tr><tr valign=\"top\"><td rowspan=\"1\" colspan=\"1\">Pulse rate</td><td rowspan=\"1\" colspan=\"1\">\\n<list list-type=\"bullet\"><list-item><p>Root mean square error of &#x02264;3&#x000a0;beats per minute</p></list-item></list>\\n</td><td rowspan=\"1\" colspan=\"1\">Most common accuracy of CE<sup>c</sup>-marked commercially available devices</td></tr><tr valign=\"top\"><td rowspan=\"1\" colspan=\"1\">Respiratory rate</td><td rowspan=\"1\" colspan=\"1\">\\n<list list-type=\"bullet\"><list-item><p>Maximum error tolerance of 5 breaths per minute</p></list-item></list>\\n</td><td rowspan=\"1\" colspan=\"1\">Accuracy of Philips Health watch, a CE-marked contact-based photoplethysmography device</td></tr><tr valign=\"top\"><td rowspan=\"1\" colspan=\"1\">Oxygen saturation</td><td rowspan=\"1\" colspan=\"1\">\\n<list list-type=\"bullet\"><list-item><p>Maximum error tolerance of 4%</p></list-item></list>\\n</td><td rowspan=\"1\" colspan=\"1\">ISO80601-2-61 standard for pulse oximeters [<xref rid=\"ref20\" ref-type=\"bibr\">20</xref>]</td></tr></tbody></table><table-wrap-foot><fn id=\"table2fn1\"><p><sup>a</sup>SBP: systolic blood pressure.</p></fn><fn id=\"table2fn2\"><p><sup>b</sup>ISO: International Organization for Standardization.</p></fn><fn id=\"table2fn3\"><p><sup>c</sup>CE: Conformit&#x000e9; Europ&#x000e9;enne.</p></fn></table-wrap-foot></table-wrap></sec><sec><title>Sample Size</title><p>The sample size cannot be formally calculated because it depends on the incremental improvement in the accuracy of Lifelight achieved through machine learning using the training data generated in the study. However, indicative sample sizes for the 4 subprotocols have been calculated by assessing the optimal data requirements to enable algorithm training toward the standards defined in <xref rid=\"table3\" ref-type=\"table\">Table 3</xref>, balanced against the practicality of achieving the targets. The split between training and testing data will be determined during the study according to the quality of the data collected.</p><p>The initial protocol anticipated data collection from about 8400 participants for training and a further 1000 for independent testing of accuracy, but the recruitment has been compromised by restrictions implemented during the COVID-19 pandemic. However, the high-quality video recording (compared with VISION-D and VISION-V) supported a protocol amendment to reduce the recruitment to 1950 participants (see Results section), with the expectation that data from about 1700 will be used for training the algorithms and data from 250 used for testing. The study management team is monitoring the progress of data collection and accuracy, and updates the study teams monthly. The study will continue until the accuracy of Lifelight for measuring VS is sufficient for various clinical use cases.</p><p>As skin tone is expected to affect the accuracy of Lifelight, the aim is to recruit participants across the full Fitzpatrick skin tone scale (1-6). To allow the impact of skin tone measurement accuracy to be determined with statistical robustness, the full data set will be sampled to create a subset for skin tone analyses in which the prevalence of the usually less prevalent skin tones is amplified. This subset will contain 750-1000 measurements, with 15%-20% each from categories 1, 2 and 3, 4, and 5 and 6. These measurements should be spread across the subprotocols as indicated in <xref rid=\"table3\" ref-type=\"table\">Table 3</xref>.</p><table-wrap position=\"float\" id=\"table3\"><label>Table 3</label><caption><p>Indicative sample size targets.</p></caption><table frame=\"hsides\" rules=\"groups\" width=\"1000\" cellpadding=\"5\" cellspacing=\"0\" border=\"1\"><col width=\"100\" span=\"1\"/><col width=\"180\" span=\"1\"/><col width=\"460\" span=\"1\"/><col width=\"260\" span=\"1\"/><thead><tr valign=\"top\"><td rowspan=\"1\" colspan=\"1\">Subprotocol</td><td rowspan=\"1\" colspan=\"1\">Indicative sample size, n<sup>a</sup></td><td rowspan=\"1\" colspan=\"1\">Characteristics</td><td rowspan=\"1\" colspan=\"1\">Participants with skin tone categories 1, 4, 5, and 6</td></tr></thead><tbody><tr valign=\"top\"><td rowspan=\"1\" colspan=\"1\">1<break/>\\n<break/>\\n</td><td rowspan=\"1\" colspan=\"1\">1500</td><td rowspan=\"1\" colspan=\"1\">Roughly 100 participants will be recruited with SOC<sup>b</sup>-determined SBP<sup>c</sup> in each 10&#x000a0;mm Hg increment from &#x0003c;90 mm Hg to &#x0003e;200&#x000a0;mm Hg (ie, &#x0003c;90 mm Hg; 90-99 mm Hg; 100-109 mm Hg, etc)<sup>d</sup><break/>\\n<break/>\\n</td><td rowspan=\"1\" colspan=\"1\">Ideally &#x02265;4 in each SBP band</td></tr><tr valign=\"top\"><td rowspan=\"1\" colspan=\"1\">2</td><td rowspan=\"1\" colspan=\"1\">375</td><td rowspan=\"1\" colspan=\"1\">N/A<sup>e</sup></td><td rowspan=\"1\" colspan=\"1\">Ideally &#x02265;10 in each SBP band</td></tr><tr valign=\"top\"><td rowspan=\"1\" colspan=\"1\">3</td><td rowspan=\"1\" colspan=\"1\">35</td><td rowspan=\"1\" colspan=\"1\">Approximately 33% with SOC-measured oxygen saturation &#x0003c;88%, 88%-92%, and 93%-95%</td><td rowspan=\"1\" colspan=\"1\">Ideally, each band will include participants with each skin tone</td></tr><tr valign=\"top\"><td rowspan=\"1\" colspan=\"1\">4</td><td rowspan=\"1\" colspan=\"1\">No specific target; likely to be a small proportion</td><td rowspan=\"1\" colspan=\"1\">N/A</td><td rowspan=\"1\" colspan=\"1\">N/A</td></tr></tbody></table><table-wrap-foot><fn id=\"table3fn1\"><p><sup>a</sup>Participants in subprotocol 4 (ie, those without the capacity to provide informed consent) are likely to have vital sign values outside of the normal range and will contribute to all subprotocol targets. Only the first study session per participant contributes to the sample size.</p></fn><fn id=\"table3fn2\"><p><sup>b</sup>SOC: standard of care.</p></fn><fn id=\"table3fn3\"><p><sup>c</sup>SBP: systolic blood pressure.</p></fn><fn id=\"table3fn4\"><p><sup>d</sup>Can include participants with SBP measured from an arterial line.</p></fn><fn id=\"table3fn5\"><p><sup>e</sup>N/A: not applicable.</p></fn></table-wrap-foot></table-wrap></sec><sec><title>Data Analysis</title><p>The training data will be used to further develop the signal extraction and processing methodology. The test data will subsequently be used to determine the performance of Lifelight against the targets set out in <xref rid=\"table2\" ref-type=\"table\">Table 2</xref>.</p><p>All statistical analyses will be performed using Microsoft Excel. All analyses will be completed per protocol since there is no intention to treat.</p><p>There will be no imputation of missing or implausible data, and any missing, implausible, or problematic readings will be excluded from the analysis. If the Lifelight software is unable to detect the participant&#x02019;s face during the measurement period, this will be recorded in the electronic case report form, and the measurements will be deleted from the data set.</p></sec></sec><sec sec-type=\"results\"><title>Results</title><p>The prototype Lifelight technology has been in development since 2016. The recruitment of participants for VISION-MD started in May 2021 but was compromised by the restrictions implemented to manage the COVID-19 pandemic, including restricting hospital access to the general public. Protocol amendments were thus made to enhance community recruitment, including the use of incentives such as chocolates or gift cards. In addition, the higher-resolution video recording (compared with the earlier VISION studies) supported reduction of the recruitment target to 1950, which is expected to yield sufficient high-quality measurements for machine learning and subsequent testing (reflected in a further protocol amendment). An additional amendment allowed the measurement of BP and pulse rate using devices other than the standard-of-care Welch Allyn devices (and indicated in the electronic case report form), as not all participating centers had the originally specified equipment.</p><p>Data for analysis will become available from September 2022, and the algorithms will be continuously refined to improve clinical accuracy. We anticipate that the final analyses to determine the performance of Lifelight against the targets set out in <xref rid=\"table2\" ref-type=\"table\">Table 2</xref> will be complete in early 2023.</p></sec><sec sec-type=\"discussion\"><title>Discussion</title><p>The VISION-MD study is expected to provide sufficient high-quality data from a wide range of healthy volunteers and patients (including critically ill patients) to further develop the accuracy of the software for estimating VS in clinical and community settings. While the VISION-V and -D studies demonstrated the potential value of Lifelight in the contactless measurement of VS and supported class I CE certification [<xref rid=\"ref15\" ref-type=\"bibr\">15</xref>], further refinement of data collection and analysis methods is needed&#x02014;particularly VS measurements outside the normal healthy range&#x02014;to develop the algorithms for clinical use.</p><p>The high-quality videos collected in the VISION-MD studies will be instrumental in training the algorithms being developed for data processing. A proportion of the data collected will be retained for testing the performance of Lifelight in estimating VS compared with the standard of care.</p><p>The study findings will be published in high-impact peer-reviewed scientific journals and presented at international cardiology, respiratory, and medical device conferences.</p></sec></body><back><ack><p>The VISION-MD protocol was codeveloped by Barts Biomedical Research Centre, Portsmouth Hospitals University NHS Trust, Mind over Matter Medtech, and Xim Ltd. This report is an independent research funded by the National Institute for Health Research (Artificial Intelligence, Developing Lifelight: A contactless vital signs monitor for CVD screening, AI_AWARD02031) and NHSX. The views expressed in this publication are those of the authors and not necessarily those of the National Institute for Health Research, NHSX, or the Department of Health and Social Care. Medical writing support was provided by Helen Barham, PhD (The Text Doctor), funded by Xim Ltd.</p><p>The contributors associated with Lifelight Trials Group are as follows: Sharon Allard, Dr Mark Lyons-Amos, Bethany Armstead, Rosalynn Austin, Rebecca Baker, Dr Michelle Baker Moffat, Armida Balawon, Debbi Barnes, Sonia Baryschpolec, Sean Beech, Selina Begum, Lauren Bell, Helen Blackman, Marie Broadway, Kate Burrows, Philippa Copnall, Zoe Daly, Joanne Dash, Mini David, Teresa Day, Jacqueline Denham, Rodrigo Dias, Alison Dimmer, Gemma Dixon, Tracey Dobson, Catherine Edwards, Carole Fogg, Dr Jim Forrer, Francis Galera, Zoe Garner, Andrew Gribbin, Elizabeth Hawes, Serena Howe, Karen Hudson, Amanda Hungate, Victoria Hunter, Jo Kerr, Adam Kiddle, Arjun Kumar, Shanqin Liu, Beverley Longhurst, Sharon McCready, Shoid Miah, Maria Moon, Kirsty Parker, Gina Pelletier, Connie Petronzio, David Petronzio, Michelle Pople, Benildo Jr Quiros, Deidre Rodgers, Dr Mike Sadler, Kerrie Scott, Josh Sephton, Samantha Smith, Bruce Stanley, Nina Szarazova, Nick Thorne, Monika Thwaites, Sarah Tronk, Catherine Tuffrey, Marcus Tuke, Charlotte Turner, James Turner, Lewis Valaitis, Dr Lieke van Putten, Lyn Vinall, Marie White, Melanie Willcox, Jonathon Winter, Carole Wragg, Kim Wren.</p></ack><fn-group><fn fn-type=\"COI-statement\"><p>Conflicts of Interest: LP is the Founder of Xim Ltd and is a major shareholder in the company.</p></fn></fn-group><glossary><title>Abbreviations</title><def-list><def-item><term id=\"abb1\">BP</term><def><p>blood pressure</p></def></def-item><def-item><term id=\"abb2\">CE</term><def><p>Conformit&#x000e9; Europ&#x000e9;enne</p></def></def-item><def-item><term id=\"abb3\">HRA</term><def><p>Health Research Authority</p></def></def-item><def-item><term id=\"abb4\">NHS</term><def><p>National Health Service</p></def></def-item><def-item><term id=\"abb5\">PPG</term><def><p>photoplethysmography</p></def></def-item><def-item><term id=\"abb6\">REDCap</term><def><p>Research Electronic Data Capture</p></def></def-item><def-item><term id=\"abb7\">rPPG</term><def><p>remote photoplethysmography</p></def></def-item><def-item><term id=\"abb8\">VS</term><def><p>vital signs</p></def></def-item><def-item><term id=\"abb9\">VISION-D</term><def><p>Measurement of Vital Signs by Lifelight Software in Comparison to the Standard of Care&#x02013;Development</p></def></def-item><def-item><term id=\"abb10\">VISION-V</term><def><p>Measurement of Vital Signs by Lifelight Software in Comparison to the Standard of Care&#x02013;Validation</p></def></def-item><def-item><term id=\"abb11\">VISION-MD</term><def><p>Measurement of Vital Signs by Lifelight Software in Comparison to the Standard of Care&#x02013;Multisite Development</p></def></def-item></def-list></glossary><notes><sec sec-type=\"data-availability\"><title>Data Availability</title><p>The data generated and analyzed during this study are commercially sensitive and are therefore not publicly available, as mandated by Xim&#x02019;s contractual obligations with its grant funders and investors. Furthermore, the informed consent provided by study participants only allows access to individual data, including in anonymized form, by authorized individuals of the research team based at the study sites, Xim, and Xim&#x02019;s authorized partners. Reasonable requests for access to the study data within these limitations will be considered by the corresponding author.</p></sec></notes><ref-list><ref id=\"ref1\"><label>1</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name><surname>Buist</surname><given-names>MD</given-names></name><name><surname>Jarmolowski</surname><given-names>E</given-names></name><name><surname>Burton</surname><given-names>PR</given-names></name><name><surname>Bernard</surname><given-names>SA</given-names></name><name><surname>Waxman</surname><given-names>BP</given-names></name><name><surname>Anderson</surname><given-names>J</given-names></name></person-group><article-title>Recognising clinical instability in hospital patients before cardiac arrest or unplanned admission to intensive care. A pilot study in a tertiary-care hospital</article-title><source>Med J Aust</source><year>1999</year><month>07</month><day>05</day><volume>171</volume><issue>1</issue><fpage>22</fpage><lpage>25</lpage><pub-id pub-id-type=\"doi\">10.5694/j.1326-5377.1999.tb123492.x</pub-id><pub-id pub-id-type=\"medline\">10451667</pub-id><pub-id pub-id-type=\"pmid\">10451667</pub-id></element-citation></ref><ref id=\"ref2\"><label>2</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name><surname>Hands</surname><given-names>C</given-names></name><name><surname>Reid</surname><given-names>E</given-names></name><name><surname>Meredith</surname><given-names>P</given-names></name><name><surname>Smith</surname><given-names>GB</given-names></name><name><surname>Prytherch</surname><given-names>DR</given-names></name><name><surname>Schmidt</surname><given-names>PE</given-names></name><name><surname>Featherstone</surname><given-names>PI</given-names></name></person-group><article-title>Patterns in the recording of vital signs and early warning scores: compliance with a clinical escalation protocol</article-title><source>BMJ Qual Saf</source><year>2013</year><month>09</month><volume>22</volume><issue>9</issue><fpage>719</fpage><lpage>726</lpage><pub-id pub-id-type=\"doi\">10.1136/bmjqs-2013-001954</pub-id><pub-id pub-id-type=\"medline\">23603474</pub-id><pub-id pub-id-type=\"pii\">bmjqs-2013-001954</pub-id></element-citation></ref><ref id=\"ref3\"><label>3</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name><surname>van Leuvan</surname><given-names>CH</given-names></name><name><surname>Mitchell</surname><given-names>I</given-names></name></person-group><article-title>Missed opportunities? An observational study of vital sign measurements</article-title><source>Crit Care Resusc</source><year>2008</year><month>06</month><volume>10</volume><issue>2</issue><fpage>111</fpage><lpage>115</lpage><pub-id pub-id-type=\"medline\">18522524</pub-id><pub-id pub-id-type=\"pmid\">18522524</pub-id></element-citation></ref><ref id=\"ref4\"><label>4</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name><surname>Ludikhuize</surname><given-names>J</given-names></name><name><surname>Smorenburg</surname><given-names>SM</given-names></name><name><surname>de Rooij</surname><given-names>SE</given-names></name><name><surname>de Jonge</surname><given-names>E</given-names></name></person-group><article-title>Identification of deteriorating patients on general wards; measurement of vital parameters and potential effectiveness of the Modified Early Warning Score</article-title><source>J Crit Care</source><year>2012</year><month>08</month><volume>27</volume><issue>4</issue><fpage>424.e7</fpage><lpage>13</lpage><pub-id pub-id-type=\"doi\">10.1016/j.jcrc.2012.01.003</pub-id><pub-id pub-id-type=\"medline\">22341727</pub-id><pub-id pub-id-type=\"pii\">S0883-9441(12)00016-0</pub-id></element-citation></ref><ref id=\"ref5\"><label>5</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name><surname>Flacco</surname><given-names>ME</given-names></name><name><surname>Manzoli</surname><given-names>L</given-names></name><name><surname>Bucci</surname><given-names>M</given-names></name><name><surname>Capasso</surname><given-names>L</given-names></name><name><surname>Comparcini</surname><given-names>D</given-names></name><name><surname>Simonetti</surname><given-names>V</given-names></name><name><surname>Gualano</surname><given-names>MR</given-names></name><name><surname>Nocciolini</surname><given-names>M</given-names></name><name><surname>D\\'Amario</surname><given-names>C</given-names></name><name><surname>Cicolini</surname><given-names>G</given-names></name></person-group><article-title>Uneven accuracy of home blood pressure measurement: a multicentric survey</article-title><source>J Clin Hypertens (Greenwich)</source><year>2015</year><month>08</month><volume>17</volume><issue>8</issue><fpage>638</fpage><lpage>643</lpage><pub-id pub-id-type=\"doi\">10.1111/jch.12552</pub-id><pub-id pub-id-type=\"doi\">10.1111/jch.12552</pub-id><pub-id pub-id-type=\"medline\">25880129</pub-id><!--<pub-id pub-id-type=\"pmcid\">PMC8032095</pub-id>--><pub-id pub-id-type=\"pmid\">25880129</pub-id></element-citation></ref><ref id=\"ref6\"><label>6</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name><surname>Kamal</surname><given-names>AA</given-names></name><name><surname>Harness</surname><given-names>JB</given-names></name><name><surname>Irving</surname><given-names>G</given-names></name><name><surname>Mearns</surname><given-names>AJ</given-names></name></person-group><article-title>Skin photoplethysmography&#x02014;a review</article-title><source>Comput Methods Programs Biomed</source><year>1989</year><month>04</month><volume>28</volume><issue>4</issue><fpage>257</fpage><lpage>269</lpage><pub-id pub-id-type=\"doi\">10.1016/0169-2607(89)90159-4</pub-id><pub-id pub-id-type=\"medline\">2649304</pub-id><pub-id pub-id-type=\"pii\">0169-2607(89)90159-4</pub-id><pub-id pub-id-type=\"pmid\">2649304</pub-id></element-citation></ref><ref id=\"ref7\"><label>7</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name><surname>Johansson</surname><given-names>A</given-names></name><name><surname>Oberg</surname><given-names>PA</given-names></name><name><surname>Sedin</surname><given-names>G</given-names></name></person-group><article-title>Monitoring of heart and respiratory rates in newborn infants using a new photoplethysmographic technique</article-title><source>J Clin Monit Comput</source><year>1999</year><month>12</month><volume>15</volume><issue>7-8</issue><fpage>461</fpage><lpage>467</lpage><pub-id pub-id-type=\"doi\">10.1023/a:1009912831366</pub-id><pub-id pub-id-type=\"medline\">12578044</pub-id><pub-id pub-id-type=\"pmid\">12578044</pub-id></element-citation></ref><ref id=\"ref8\"><label>8</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name><surname>Poh</surname><given-names>M</given-names></name><name><surname>Poh</surname><given-names>YC</given-names></name></person-group><article-title>Validation of a standalone smartphone application for measuring heart rate using imaging photoplethysmography</article-title><source>Telemed J E Health</source><year>2017</year><month>08</month><volume>23</volume><issue>8</issue><fpage>678</fpage><lpage>683</lpage><pub-id pub-id-type=\"doi\">10.1089/tmj.2016.0230</pub-id><pub-id pub-id-type=\"medline\">28140834</pub-id><pub-id pub-id-type=\"pmid\">28140834</pub-id></element-citation></ref><ref id=\"ref9\"><label>9</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name><surname>Aoyagi</surname><given-names>T</given-names></name><name><surname>Miyasaka</surname><given-names>K</given-names></name></person-group><article-title>Pulse oximetry: its invention, contribution to medicine, and future tasks</article-title><source>Anesth Analg</source><year>2002</year><month>01</month><volume>94</volume><issue>1 Suppl</issue><fpage>S1</fpage><lpage>3</lpage><pub-id pub-id-type=\"medline\">11900029</pub-id></element-citation></ref><ref id=\"ref10\"><label>10</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name><surname>Elgendi</surname><given-names>M</given-names></name><name><surname>Fletcher</surname><given-names>R</given-names></name><name><surname>Liang</surname><given-names>Y</given-names></name><name><surname>Howard</surname><given-names>N</given-names></name><name><surname>Lovell</surname><given-names>NH</given-names></name><name><surname>Abbott</surname><given-names>D</given-names></name><name><surname>Lim</surname><given-names>K</given-names></name><name><surname>Ward</surname><given-names>R</given-names></name></person-group><article-title>The use of photoplethysmography for assessing hypertension</article-title><source>NPJ Digit Med</source><year>2019</year><volume>2</volume><fpage>60</fpage><pub-id pub-id-type=\"doi\">10.1038/s41746-019-0136-7</pub-id><pub-id pub-id-type=\"doi\">10.1038/s41746-019-0136-7</pub-id><pub-id pub-id-type=\"medline\">31388564</pub-id><pub-id pub-id-type=\"pii\">136</pub-id><!--<pub-id pub-id-type=\"pmcid\">PMC6594942</pub-id>--><pub-id pub-id-type=\"pmid\">31388564</pub-id></element-citation></ref><ref id=\"ref11\"><label>11</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name><surname>Radha</surname><given-names>M</given-names></name><name><surname>de Groot</surname><given-names>K</given-names></name><name><surname>Rajani</surname><given-names>N</given-names></name><name><surname>Wong</surname><given-names>CCP</given-names></name><name><surname>Kobold</surname><given-names>N</given-names></name><name><surname>Vos</surname><given-names>V</given-names></name><name><surname>Fonseca</surname><given-names>P</given-names></name><name><surname>Mastellos</surname><given-names>N</given-names></name><name><surname>Wark</surname><given-names>PA</given-names></name><name><surname>Velthoven</surname><given-names>N</given-names></name><name><surname>Haakma</surname><given-names>R</given-names></name><name><surname>Aarts</surname><given-names>RM</given-names></name></person-group><article-title>Estimating blood pressure trends and the nocturnal dip from photoplethysmography</article-title><source>Physiol Meas</source><year>2019</year><month>02</month><day>26</day><volume>40</volume><issue>2</issue><fpage>025006</fpage><pub-id pub-id-type=\"doi\">10.1088/1361-6579/ab030e</pub-id><pub-id pub-id-type=\"medline\">30699397</pub-id><pub-id pub-id-type=\"pmid\">30699397</pub-id></element-citation></ref><ref id=\"ref12\"><label>12</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name><surname>Nilsson</surname><given-names>L</given-names></name><name><surname>Johansson</surname><given-names>A</given-names></name><name><surname>Kalman</surname><given-names>S</given-names></name></person-group><article-title>Monitoring of respiratory rate in postoperative care using a new photoplethysmographic technique</article-title><source>J Clin Monit Comput</source><year>2000</year><volume>16</volume><issue>4</issue><fpage>309</fpage><lpage>315</lpage><pub-id pub-id-type=\"doi\">10.1023/a:1011424732717</pub-id><pub-id pub-id-type=\"medline\">12578078</pub-id><pub-id pub-id-type=\"pmid\">12578078</pub-id></element-citation></ref><ref id=\"ref13\"><label>13</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name><surname>Sun</surname><given-names>Y</given-names></name><name><surname>Yang</surname><given-names>Y</given-names></name><name><surname>Wu</surname><given-names>B</given-names></name><name><surname>Huang</surname><given-names>P</given-names></name><name><surname>Cheng</surname><given-names>S</given-names></name><name><surname>Wu</surname><given-names>B</given-names></name><name><surname>Chen</surname><given-names>C</given-names></name></person-group><article-title>Contactless facial video recording with deep learning models for the detection of atrial fibrillation</article-title><source>Sci Rep</source><year>2022</year><month>01</month><day>07</day><volume>12</volume><issue>1</issue><fpage>281</fpage><pub-id pub-id-type=\"doi\">10.1038/s41598-021-03453-y</pub-id><pub-id pub-id-type=\"doi\">10.1038/s41598-021-03453-y</pub-id><pub-id pub-id-type=\"medline\">34996908</pub-id><pub-id pub-id-type=\"pii\">10.1038/s41598-021-03453-y</pub-id><!--<pub-id pub-id-type=\"pmcid\">PMC8741942</pub-id>--><pub-id pub-id-type=\"pmid\">34996908</pub-id></element-citation></ref><ref id=\"ref14\"><label>14</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name><surname>Heiden</surname><given-names>E</given-names></name><name><surname>Jones</surname><given-names>T</given-names></name></person-group><article-title>Measurement of vital signs using Lifelight&#x000ae; Remote Photoplethysmography: results of the VISION-D and VISION-V observational studies</article-title><source>JMIR Form Res</source><year>2022</year><volume>6</volume><issue>11</issue><fpage>e36340</fpage><comment>\\n<ext-link xlink:href=\"https://formative.jmir.org/2022/11/e36340\" ext-link-type=\"uri\"/>\\n</comment><pub-id pub-id-type=\"doi\">10.2196/36340</pub-id><pub-id pub-id-type=\"pmid\">36374541</pub-id></element-citation></ref><ref id=\"ref15\"><label>15</label><element-citation publication-type=\"webpage\"><article-title>Medtech innovation briefing MIB213: Lifelight First for monitoring vital signs 2020</article-title><source>National Institute for Health and Care Excellence</source><year>2022</year><date-in-citation content-type=\"access-date\">2022-10-11</date-in-citation><comment>\\n<ext-link xlink:href=\"https://www.nice.org.uk/advice/mib213/chapter/The-technology\" ext-link-type=\"uri\">https://www.nice.org.uk/advice/mib213/chapter/The-technology</ext-link>\\n</comment></element-citation></ref><ref id=\"ref16\"><label>16</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name><surname>Kwon</surname><given-names>S</given-names></name><name><surname>Kim</surname><given-names>J</given-names></name><name><surname>Lee</surname><given-names>D</given-names></name><name><surname>Park</surname><given-names>K</given-names></name></person-group><article-title>ROI analysis for remote photoplethysmography on facial video</article-title><source>Annu Int Conf IEEE Eng Med Biol Soc</source><year>2015</year><month>08</month><fpage>4938</fpage><lpage>4941</lpage><pub-id pub-id-type=\"doi\">10.1109/EMBC.2015.7319499</pub-id><pub-id pub-id-type=\"medline\">26737399</pub-id><pub-id pub-id-type=\"pmid\">26737399</pub-id></element-citation></ref><ref id=\"ref17\"><label>17</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name><surname>Kashima</surname><given-names>H</given-names></name><name><surname>Ikemura</surname><given-names>T</given-names></name><name><surname>Hayashi</surname><given-names>N</given-names></name></person-group><article-title>Regional differences in facial skin blood flow responses to the cold pressor and static handgrip tests</article-title><source>Eur J Appl Physiol</source><year>2013</year><month>04</month><volume>113</volume><issue>4</issue><fpage>1035</fpage><lpage>1041</lpage><pub-id pub-id-type=\"doi\">10.1007/s00421-012-2522-6</pub-id><pub-id pub-id-type=\"medline\">23064980</pub-id><pub-id pub-id-type=\"pmid\">23064980</pub-id></element-citation></ref><ref id=\"ref18\"><label>18</label><element-citation publication-type=\"journal\"><person-group person-group-type=\"author\"><name><surname>Colvonen</surname><given-names>PJ</given-names></name></person-group><article-title>Response to: investigating sources of inaccuracy in wearable optical heart rate sensors</article-title><source>NPJ Digit Med</source><year>2021</year><month>02</month><day>26</day><volume>4</volume><issue>1</issue><fpage>38</fpage><pub-id pub-id-type=\"doi\">10.1038/s41746-021-00408-5</pub-id><pub-id pub-id-type=\"doi\">10.1038/s41746-021-00408-5</pub-id><pub-id pub-id-type=\"medline\">33637822</pub-id><pub-id pub-id-type=\"pii\">10.1038/s41746-021-00408-5</pub-id><!--<pub-id pub-id-type=\"pmcid\">PMC7910598</pub-id>--><pub-id pub-id-type=\"pmid\">33637822</pub-id></element-citation></ref><ref id=\"ref19\"><label>19</label><element-citation publication-type=\"webpage\"><article-title>ISO 81060-2+A1: non-invasive sphygmomanometers&#x02014; part 2: clinical investigation of intermittent automated measurement type</article-title><source>ISO</source><year>2019</year><date-in-citation content-type=\"access-date\">2022-10-11</date-in-citation><comment>\\n<ext-link xlink:href=\"https://www.iso.org/standard/73339.html\" ext-link-type=\"uri\">https://www.iso.org/standard/73339.html</ext-link>\\n</comment></element-citation></ref><ref id=\"ref20\"><label>20</label><element-citation publication-type=\"webpage\"><article-title>ISO 80601-2-61: medical electrical equipment&#x02014; part 2-61: particular requirements for basic safety and essential performance of pulse oximeter equipment</article-title><source>ISO</source><year>2019</year><date-in-citation content-type=\"access-date\">2022-10-11</date-in-citation><comment>\\n<ext-link xlink:href=\"https://www.iso.org/standard/67963.html\" ext-link-type=\"uri\">https://www.iso.org/standard/67963.html</ext-link>\\n</comment></element-citation></ref></ref-list></back></article>'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss[191]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d83ba89-8992-4750-a830-813f3de5d4c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "48218ad2-b0c4-483b-a9de-93ec3407d554",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix keywords\n",
    "\n",
    "#<kwd-group><kwd>astrocyte</kwd><kwd>microglia</kwd><kwd>excitability</kwd><kwd>hydrogen sulfide</kwd><kwd>BDNF</kwd><kwd>polyamine</kwd><kwd>dexmedetomidine</kwd><kwd>astrocyte-microglia co-culture</kwd></kwd-group>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080d58e0-ba2d-42eb-8a94-f06ab9a44bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "<title>Author contributions</title> # titles are repeating, take care"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd26a39-2dbe-44bb-bfe6-267e59a87dd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
